{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX TITAN X\n"
     ]
    }
   ],
   "source": [
    "# Edgar data Aug 2023\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "from loguru import logger\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from preprocessing import *\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = Path('./data/biological/')\n",
    "stim_path = parent_path / \"AUG23/\"\n",
    "save_path = Path('./save/trained_models/AUG23/')\n",
    "\n",
    "area_ID_ephys = np.load(stim_path / 'area_idx.npy')        # (106,) 8 LS, 70 ACC\n",
    "dff_stim = np.load(stim_path /'img_array.npy')                  # (189, 19010) GCaMP when stimulated \n",
    "spks_stim_1hz = np.load(stim_path /'ephys_array.npy')                # (92, 536020)\n",
    "\n",
    "dff_stim_times_a = np.load(stim_path / 'img_stim_a.npy').reshape(-1,1)\n",
    "ephys_stim_times_a = np.load(stim_path / 'ephys_stim_a.npy').reshape(-1,1)\n",
    "ephys_stim_times_b = np.load(stim_path / 'ephys_stim_b.npy').reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65679/957492132.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  spks_stim_shifted = spks_stim_1hz[:, int(ephys_offset):]\n"
     ]
    }
   ],
   "source": [
    "# align stim instances with stim_a\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(dff_stim_times_a, ephys_stim_times_a) # ephys at 1Hz, dff at 30 Hz. \n",
    "bin_size = lr.coef_.flatten() # bin size\n",
    "ephys_offset = lr.intercept_ # y-intercept\n",
    "\n",
    "# ephys_time = 7478 + 33.29 * dff \n",
    "# i.e. dFF = 0, Ephys= 7478 needs to shift Ephys back by 7874\n",
    "# check error\n",
    "\n",
    "assert np.sum(np.round((ephys_stim_times_a.T - ephys_offset) / bin_size) - dff_stim_times_a.T) < 1\n",
    "\n",
    "spks_stim_shifted = spks_stim_1hz[:, int(ephys_offset):]\n",
    "from utils import bin_spikes\n",
    "spks_stim = bin_spikes(spks_stim_shifted, bin_size)\n",
    "stim_time = np.round((np.array(sorted(list(set(list(ephys_stim_times_a.T[0]) + list(ephys_stim_times_b.T[0]))))) - ephys_offset) / bin_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolve spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 12:43:15.936 | INFO     | preprocessing:convolve_spikes:26 - Detected Ephys file with 92 neurons and 15872 bins.\n",
      "2024-03-21 12:43:16.020 | INFO     | preprocessing:convolve_spikes:51 - Produced convolved rates at sigma=0.1 with 92 neurons and 15872 bins.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spks_stim_rates, n_output_neurons, n_bins = convolve_spikes(spks_stim)\n",
    "plot_convolution_example(spks_stim_rates, spks_stim,seed=seed)\n",
    "input_dim = dff_stim.shape[0]\n",
    "# assert n_bins == dff_stim.shape[1]\n",
    "# asertion error: truncate dff_stim\n",
    "dff_stim = dff_stim[:, :n_bins]\n",
    "stim_time = stim_time[stim_time < n_bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS neuron firing rate: 22.714384078979492 Hz\n",
      "non-LS neuron firing rate: 55.002647399902344 Hz\n"
     ]
    }
   ],
   "source": [
    "mask1 = area_ID_ephys == 'LS'\n",
    "mask2 = area_ID_ephys != 'LS'\n",
    "\n",
    "plt.bar(np.arange(spks_stim_rates.shape[1])[mask1], spks_stim_rates.mean(0)[mask1], color='red', label='LS')\n",
    "plt.bar(np.arange(spks_stim_rates.shape[1])[mask2], spks_stim_rates.mean(0)[mask2], color='blue', label='Others')\n",
    "plt.axhline(spks_stim_rates.mean(0)[mask1].mean(), linestyle='--', color='red')\n",
    "plt.axhline(spks_stim_rates.mean(0)[mask2].mean(), linestyle='--', color='blue')\n",
    "plt.legend()\n",
    "plt.xlabel('Neuron index')\n",
    "plt.ylabel('Smoothened firing rate (Hz)')\n",
    "plt.show()\n",
    "print(f'LS neuron firing rate: {spks_stim_rates.mean(0)[mask1].mean()} Hz')\n",
    "print(f'non-LS neuron firing rate: {spks_stim_rates.mean(0)[mask2].mean()} Hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Stim instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_ID = ['D' for _ in range(len(stim_time))] # dummy stim_ID\n",
    "inputs, targets, non_stim_vecs_idx, stim_vecs_idx = preprocess_dff_rate_pairs(dff_stim, spks_stim_rates, has_stim=True, stim_time=stim_time, stim_ID=stim_ID, cutoff_size=1, offset=-3, tsteps=15)\n",
    "sampled_non_stim_vecs = sample_non_stim_vecs(non_stim_vecs_idx, cutoff_size=1, n=200, seed=seed)\n",
    "test_set_idx = np.concatenate([stim_vecs_idx, sampled_non_stim_vecs])\n",
    "X_train, Y_train = inputs[non_stim_vecs_idx], targets[non_stim_vecs_idx]\n",
    "X_test, Y_test = inputs[test_set_idx], targets[test_set_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LS Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_neuron_idx = np.where(area_ID_ephys == 'LS')[0]\n",
    "ACC_neuron_idx = np.where(area_ID_ephys == 'ACC')[0]\n",
    "Others_neuron_idx = np.where(area_ID_ephys == 'Other')[0]\n",
    "nLS_neuron_idx = np.where(area_ID_ephys != 'LS')[0]\n",
    "\n",
    "# randomise valid idx\n",
    "n_non_stim = len(Y_train)\n",
    "valid_idx = np.random.choice(np.arange(len(Y_train)), int(n_non_stim * 0.10))\n",
    "train_idx = np.array(list((set(np.arange(len(Y_train))) - set(valid_idx))))\n",
    "\n",
    "stim_ID = ['D' for _ in range(len(stim_time))]\n",
    "forward_mse_idx = list(np.nonzero(np.array(stim_ID) == 'F')[0])\n",
    "backward_mse_idx = list(np.nonzero(np.array(stim_ID) == 'R')[0])\n",
    "random_mse_idx = list(np.nonzero(np.array(stim_ID) == 'S')[0])\n",
    "non_stim_mse_idx = np.arange(len(stim_ID), Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 neurons are lateral septal according to Edgar\n",
    "Y_train_LS = Y_train[train_idx,:,:][..., LS_neuron_idx]\n",
    "Y_test_LS = Y_test[..., LS_neuron_idx]\n",
    "Y_valid_LS = Y_train[valid_idx,:,:][..., LS_neuron_idx]\n",
    "\n",
    "output_dim = len(LS_neuron_idx)\n",
    "\n",
    "batch_size = 1024\n",
    "train_dataset = BNN_Dataset(X_train[train_idx, ...], Y_train_LS)\n",
    "train_dataloader_LS = DataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "test_dataset = BNN_Dataset(X_test, Y_test_LS)\n",
    "test_dataloader_LS = DataLoader(test_dataset, batch_size=len(test_dataset), drop_last=False, shuffle=False)\n",
    "valid_dataset = BNN_Dataset(X_train[valid_idx, ...], Y_valid_LS)\n",
    "valid_dataloader_LS = DataLoader(valid_dataset, batch_size=len(valid_dataset), drop_last=False, shuffle=False)\n",
    "del train_dataset, test_dataset, valid_dataset\n",
    "\n",
    "# fit GLM with identity link function\n",
    "X_train_np = X_train[train_idx, ...].cpu().numpy().reshape(X_train[train_idx, ...].shape[0],-1)\n",
    "Y_train_LS_np = Y_train_LS.cpu().numpy().reshape(Y_train_LS.shape[0],-1) + 1e-6 # numerical stability\n",
    "\n",
    "X_test_np = X_test.cpu().numpy().reshape(X_test.shape[0],-1)\n",
    "Y_test_LS_np = Y_test_LS.cpu().numpy().reshape(Y_test_LS.shape[0],-1) + 1e-6 # numerical stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  d_model  | hidden... | n_layers  | num_heads |\n",
      "-------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 76%|███████▌  | 189/250 [00:25<00:08,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m1        \u001b[0m | \u001b[0m-209.1   \u001b[0m | \u001b[0m1.423e+03\u001b[0m | \u001b[0m357.5    \u001b[0m | \u001b[0m1.907    \u001b[0m | \u001b[0m16.99    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 166/250 [01:42<00:51,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m2        \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.467e+03\u001b[0m | \u001b[0m480.8    \u001b[0m | \u001b[0m4.923    \u001b[0m | \u001b[0m20.86    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 191/250 [00:36<00:11,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m3        \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.014e+03\u001b[0m | \u001b[0m452.9    \u001b[0m | \u001b[0m2.373    \u001b[0m | \u001b[0m22.14    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 189/250 [00:31<00:10,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m4        \u001b[0m | \u001b[0m-267.5   \u001b[0m | \u001b[0m933.3    \u001b[0m | \u001b[0m153.7    \u001b[0m | \u001b[0m2.592    \u001b[0m | \u001b[0m22.4     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:26<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m5        \u001b[0m | \u001b[0m-238.3   \u001b[0m | \u001b[0m446.7    \u001b[0m | \u001b[0m257.9    \u001b[0m | \u001b[0m3.126    \u001b[0m | \u001b[0m16.42    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 172/250 [01:14<00:33,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m6        \u001b[0m | \u001b[0m-268.2   \u001b[0m | \u001b[0m1.305e+03\u001b[0m | \u001b[0m864.5    \u001b[0m | \u001b[0m3.898    \u001b[0m | \u001b[0m18.72    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 167/250 [00:55<00:27,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m7        \u001b[0m | \u001b[0m-268.2   \u001b[0m | \u001b[0m1.473e+03\u001b[0m | \u001b[0m390.7    \u001b[0m | \u001b[0m2.447    \u001b[0m | \u001b[0m7.62     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 231/250 [00:15<00:01, 14.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m8        \u001b[0m | \u001b[0m-229.4   \u001b[0m | \u001b[0m658.1    \u001b[0m | \u001b[0m667.9    \u001b[0m | \u001b[0m1.368    \u001b[0m | \u001b[0m13.58    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 192/250 [00:34<00:10,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m9        \u001b[0m | \u001b[0m-268.7   \u001b[0m | \u001b[0m918.6    \u001b[0m | \u001b[0m544.3    \u001b[0m | \u001b[0m2.703    \u001b[0m | \u001b[0m10.06    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 193/250 [01:08<00:20,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m10       \u001b[0m | \u001b[0m-266.6   \u001b[0m | \u001b[0m910.1    \u001b[0m | \u001b[0m904.1    \u001b[0m | \u001b[0m4.777    \u001b[0m | \u001b[0m15.55    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 178/250 [00:47<00:19,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m11       \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.286e+03\u001b[0m | \u001b[0m204.1    \u001b[0m | \u001b[0m2.269    \u001b[0m | \u001b[0m13.03    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 161/250 [01:11<00:39,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m12       \u001b[0m | \u001b[0m-269.0   \u001b[0m | \u001b[0m1.746e+03\u001b[0m | \u001b[0m325.4    \u001b[0m | \u001b[0m2.932    \u001b[0m | \u001b[0m29.58    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 204/250 [00:24<00:05,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m13       \u001b[0m | \u001b[0m-221.8   \u001b[0m | \u001b[0m1.087e+03\u001b[0m | \u001b[0m651.6    \u001b[0m | \u001b[0m1.483    \u001b[0m | \u001b[0m24.96    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 174/250 [00:43<00:18,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m14       \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.246e+03\u001b[0m | \u001b[0m590.6    \u001b[0m | \u001b[0m2.371    \u001b[0m | \u001b[0m9.82     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 193/250 [01:03<00:18,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m15       \u001b[0m | \u001b[0m-267.7   \u001b[0m | \u001b[0m892.3    \u001b[0m | \u001b[0m713.2    \u001b[0m | \u001b[0m4.502    \u001b[0m | \u001b[0m15.8     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 172/250 [01:11<00:32,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m16       \u001b[0m | \u001b[0m-268.2   \u001b[0m | \u001b[0m1.372e+03\u001b[0m | \u001b[0m627.3    \u001b[0m | \u001b[0m3.5      \u001b[0m | \u001b[0m20.57    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 163/250 [01:51<00:59,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m17       \u001b[0m | \u001b[0m-269.0   \u001b[0m | \u001b[0m1.7e+03  \u001b[0m | \u001b[0m174.9    \u001b[0m | \u001b[0m4.055    \u001b[0m | \u001b[0m8.066    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 237/250 [00:13<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m18       \u001b[0m | \u001b[0m-244.6   \u001b[0m | \u001b[0m469.0    \u001b[0m | \u001b[0m615.2    \u001b[0m | \u001b[0m1.383    \u001b[0m | \u001b[0m26.67    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 194/250 [00:30<00:08,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m19       \u001b[0m | \u001b[0m-220.9   \u001b[0m | \u001b[0m1.292e+03\u001b[0m | \u001b[0m751.1    \u001b[0m | \u001b[0m1.065    \u001b[0m | \u001b[0m18.24    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 219/250 [00:24<00:03,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m20       \u001b[0m | \u001b[0m-217.2   \u001b[0m | \u001b[0m1.158e+03\u001b[0m | \u001b[0m243.1    \u001b[0m | \u001b[0m1.612    \u001b[0m | \u001b[0m21.17    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 218/250 [00:39<00:05,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m21       \u001b[0m | \u001b[0m-266.7   \u001b[0m | \u001b[0m705.7    \u001b[0m | \u001b[0m722.8    \u001b[0m | \u001b[0m3.218    \u001b[0m | \u001b[0m12.28    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 161/250 [01:11<00:39,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m22       \u001b[0m | \u001b[0m-268.9   \u001b[0m | \u001b[0m1.858e+03\u001b[0m | \u001b[0m857.5    \u001b[0m | \u001b[0m2.43     \u001b[0m | \u001b[0m2.264    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 220/250 [00:44<00:06,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m23       \u001b[0m | \u001b[0m-266.8   \u001b[0m | \u001b[0m679.1    \u001b[0m | \u001b[0m458.4    \u001b[0m | \u001b[0m3.82     \u001b[0m | \u001b[0m29.87    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 215/250 [00:45<00:07,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m24       \u001b[0m | \u001b[0m-266.7   \u001b[0m | \u001b[0m776.2    \u001b[0m | \u001b[0m786.3    \u001b[0m | \u001b[0m3.373    \u001b[0m | \u001b[0m21.06    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:08<00:00, 28.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m25       \u001b[0m | \u001b[0m-240.2   \u001b[0m | \u001b[0m387.1    \u001b[0m | \u001b[0m459.0    \u001b[0m | \u001b[0m1.963    \u001b[0m | \u001b[0m10.96    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 219/250 [00:23<00:03,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m26       \u001b[0m | \u001b[0m-227.7   \u001b[0m | \u001b[0m1.075e+03\u001b[0m | \u001b[0m700.0    \u001b[0m | \u001b[0m1.424    \u001b[0m | \u001b[0m4.796    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 212/250 [00:55<00:10,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m27       \u001b[0m | \u001b[0m-267.6   \u001b[0m | \u001b[0m711.8    \u001b[0m | \u001b[0m695.4    \u001b[0m | \u001b[0m4.386    \u001b[0m | \u001b[0m17.04    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 159/250 [01:04<00:36,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m28       \u001b[0m | \u001b[0m-268.8   \u001b[0m | \u001b[0m1.723e+03\u001b[0m | \u001b[0m446.4    \u001b[0m | \u001b[0m2.267    \u001b[0m | \u001b[0m11.27    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:24<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m29       \u001b[0m | \u001b[0m-233.3   \u001b[0m | \u001b[0m425.1    \u001b[0m | \u001b[0m846.2    \u001b[0m | \u001b[0m2.355    \u001b[0m | \u001b[0m17.02    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 200/250 [00:28<00:07,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m30       \u001b[0m | \u001b[0m-218.5   \u001b[0m | \u001b[0m1.199e+03\u001b[0m | \u001b[0m569.4    \u001b[0m | \u001b[0m1.011    \u001b[0m | \u001b[0m29.66    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 161/250 [01:07<00:37,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m31       \u001b[0m | \u001b[0m-269.4   \u001b[0m | \u001b[0m1.82e+03 \u001b[0m | \u001b[0m286.9    \u001b[0m | \u001b[0m2.17     \u001b[0m | \u001b[0m16.08    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 157/250 [01:16<00:45,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m32       \u001b[0m | \u001b[0m-268.7   \u001b[0m | \u001b[0m1.814e+03\u001b[0m | \u001b[0m985.3    \u001b[0m | \u001b[0m2.03     \u001b[0m | \u001b[0m17.37    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 160/250 [01:25<00:47,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m33       \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.633e+03\u001b[0m | \u001b[0m454.9    \u001b[0m | \u001b[0m3.924    \u001b[0m | \u001b[0m5.671    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 173/250 [01:27<00:38,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m34       \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.241e+03\u001b[0m | \u001b[0m879.3    \u001b[0m | \u001b[0m4.934    \u001b[0m | \u001b[0m3.302    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 198/250 [00:32<00:08,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m35       \u001b[0m | \u001b[0m-266.6   \u001b[0m | \u001b[0m913.9    \u001b[0m | \u001b[0m284.1    \u001b[0m | \u001b[0m2.803    \u001b[0m | \u001b[0m16.89    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:26<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m36       \u001b[0m | \u001b[0m-253.0   \u001b[0m | \u001b[0m277.3    \u001b[0m | \u001b[0m367.2    \u001b[0m | \u001b[0m4.71     \u001b[0m | \u001b[0m17.5     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 194/250 [00:48<00:13,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m37       \u001b[0m | \u001b[0m-267.9   \u001b[0m | \u001b[0m969.1    \u001b[0m | \u001b[0m778.2    \u001b[0m | \u001b[0m3.967    \u001b[0m | \u001b[0m2.409    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 190/250 [00:35<00:11,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m38       \u001b[0m | \u001b[0m-211.6   \u001b[0m | \u001b[0m1.447e+03\u001b[0m | \u001b[0m855.3    \u001b[0m | \u001b[0m1.664    \u001b[0m | \u001b[0m23.65    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 227/250 [00:31<00:03,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m39       \u001b[0m | \u001b[0m-264.4   \u001b[0m | \u001b[0m644.4    \u001b[0m | \u001b[0m375.8    \u001b[0m | \u001b[0m3.661    \u001b[0m | \u001b[0m4.23     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 171/250 [01:17<00:35,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m40       \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m1.363e+03\u001b[0m | \u001b[0m899.1    \u001b[0m | \u001b[0m3.785    \u001b[0m | \u001b[0m13.77    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 200/250 [00:54<00:13,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m41       \u001b[0m | \u001b[0m-267.3   \u001b[0m | \u001b[0m932.6    \u001b[0m | \u001b[0m788.6    \u001b[0m | \u001b[0m3.263    \u001b[0m | \u001b[0m3.462    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 177/250 [00:51<00:21,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m42       \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.207e+03\u001b[0m | \u001b[0m833.4    \u001b[0m | \u001b[0m2.348    \u001b[0m | \u001b[0m27.9     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 165/250 [01:46<00:55,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m43       \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.526e+03\u001b[0m | \u001b[0m616.7    \u001b[0m | \u001b[0m4.007    \u001b[0m | \u001b[0m3.295    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 168/250 [02:13<01:05,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m44       \u001b[0m | \u001b[0m-267.7   \u001b[0m | \u001b[0m1.733e+03\u001b[0m | \u001b[0m839.4    \u001b[0m | \u001b[0m4.639    \u001b[0m | \u001b[0m4.73     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m45       \u001b[0m | \u001b[0m-258.8   \u001b[0m | \u001b[0m255.4    \u001b[0m | \u001b[0m224.6    \u001b[0m | \u001b[0m2.598    \u001b[0m | \u001b[0m13.3     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 196/250 [00:23<00:06,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m46       \u001b[0m | \u001b[0m-226.1   \u001b[0m | \u001b[0m1.168e+03\u001b[0m | \u001b[0m210.0    \u001b[0m | \u001b[0m1.806    \u001b[0m | \u001b[0m24.54    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 213/250 [00:22<00:03,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m47       \u001b[0m | \u001b[0m-217.2   \u001b[0m | \u001b[0m989.2    \u001b[0m | \u001b[0m827.1    \u001b[0m | \u001b[0m1.03     \u001b[0m | \u001b[0m17.0     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 183/250 [00:48<00:17,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m48       \u001b[0m | \u001b[0m-209.8   \u001b[0m | \u001b[0m1.871e+03\u001b[0m | \u001b[0m624.0    \u001b[0m | \u001b[0m1.824    \u001b[0m | \u001b[0m21.81    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 224/250 [00:19<00:02, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m49       \u001b[0m | \u001b[0m-222.2   \u001b[0m | \u001b[0m820.1    \u001b[0m | \u001b[0m701.5    \u001b[0m | \u001b[0m1.117    \u001b[0m | \u001b[0m19.44    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 24.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m50       \u001b[0m | \u001b[0m-292.7   \u001b[0m | \u001b[0m161.2    \u001b[0m | \u001b[0m770.3    \u001b[0m | \u001b[0m2.892    \u001b[0m | \u001b[0m4.531    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 182/250 [01:03<00:23,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m51       \u001b[0m | \u001b[0m-267.7   \u001b[0m | \u001b[0m1.131e+03\u001b[0m | \u001b[0m160.1    \u001b[0m | \u001b[0m3.613    \u001b[0m | \u001b[0m29.89    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 188/250 [00:40<00:13,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m52       \u001b[0m | \u001b[0m-211.9   \u001b[0m | \u001b[0m1.562e+03\u001b[0m | \u001b[0m616.4    \u001b[0m | \u001b[0m1.411    \u001b[0m | \u001b[0m21.3     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 180/250 [01:30<00:35,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m53       \u001b[0m | \u001b[0m-267.6   \u001b[0m | \u001b[0m1.356e+03\u001b[0m | \u001b[0m144.2    \u001b[0m | \u001b[0m4.169    \u001b[0m | \u001b[0m16.04    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 203/250 [00:35<00:08,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m54       \u001b[0m | \u001b[0m-264.6   \u001b[0m | \u001b[0m909.1    \u001b[0m | \u001b[0m809.4    \u001b[0m | \u001b[0m2.646    \u001b[0m | \u001b[0m14.95    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:31<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m55       \u001b[0m | \u001b[0m-234.4   \u001b[0m | \u001b[0m445.1    \u001b[0m | \u001b[0m389.2    \u001b[0m | \u001b[0m4.382    \u001b[0m | \u001b[0m6.42     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 205/250 [00:23<00:05,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m56       \u001b[0m | \u001b[0m-228.5   \u001b[0m | \u001b[0m892.9    \u001b[0m | \u001b[0m990.1    \u001b[0m | \u001b[0m1.946    \u001b[0m | \u001b[0m27.59    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 176/250 [01:24<00:35,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m57       \u001b[0m | \u001b[0m-248.4   \u001b[0m | \u001b[0m1.845e+03\u001b[0m | \u001b[0m182.2    \u001b[0m | \u001b[0m2.855    \u001b[0m | \u001b[0m15.56    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 238/250 [00:14<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m58       \u001b[0m | \u001b[0m-227.2   \u001b[0m | \u001b[0m696.0    \u001b[0m | \u001b[0m142.6    \u001b[0m | \u001b[0m1.967    \u001b[0m | \u001b[0m3.77     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 241/250 [00:44<00:01,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m59       \u001b[0m | \u001b[0m-266.9   \u001b[0m | \u001b[0m552.7    \u001b[0m | \u001b[0m827.0    \u001b[0m | \u001b[0m4.58     \u001b[0m | \u001b[0m2.253    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 206/250 [00:44<00:09,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m60       \u001b[0m | \u001b[0m-262.2   \u001b[0m | \u001b[0m673.7    \u001b[0m | \u001b[0m982.5    \u001b[0m | \u001b[0m3.158    \u001b[0m | \u001b[0m19.16    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:18<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m61       \u001b[0m | \u001b[0m-359.8   \u001b[0m | \u001b[0m110.5    \u001b[0m | \u001b[0m536.4    \u001b[0m | \u001b[0m4.953    \u001b[0m | \u001b[0m11.88    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:25<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m62       \u001b[0m | \u001b[0m-247.4   \u001b[0m | \u001b[0m284.4    \u001b[0m | \u001b[0m515.7    \u001b[0m | \u001b[0m4.852    \u001b[0m | \u001b[0m10.91    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 180/250 [00:36<00:14,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m63       \u001b[0m | \u001b[0m-224.4   \u001b[0m | \u001b[0m1.618e+03\u001b[0m | \u001b[0m819.0    \u001b[0m | \u001b[0m1.833    \u001b[0m | \u001b[0m13.86    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 186/250 [00:30<00:10,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m64       \u001b[0m | \u001b[0m-215.9   \u001b[0m | \u001b[0m1.46e+03 \u001b[0m | \u001b[0m469.5    \u001b[0m | \u001b[0m1.764    \u001b[0m | \u001b[0m29.06    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 197/250 [00:29<00:07,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m65       \u001b[0m | \u001b[0m-224.2   \u001b[0m | \u001b[0m1.336e+03\u001b[0m | \u001b[0m878.9    \u001b[0m | \u001b[0m1.101    \u001b[0m | \u001b[0m8.74     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 190/250 [01:04<00:20,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m66       \u001b[0m | \u001b[0m-266.6   \u001b[0m | \u001b[0m1.054e+03\u001b[0m | \u001b[0m160.7    \u001b[0m | \u001b[0m4.972    \u001b[0m | \u001b[0m7.857    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 233/250 [00:16<00:01, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m67       \u001b[0m | \u001b[0m-217.6   \u001b[0m | \u001b[0m811.2    \u001b[0m | \u001b[0m292.6    \u001b[0m | \u001b[0m1.422    \u001b[0m | \u001b[0m7.742    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 245/250 [00:28<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m68       \u001b[0m | \u001b[0m-221.5   \u001b[0m | \u001b[0m671.2    \u001b[0m | \u001b[0m671.0    \u001b[0m | \u001b[0m2.125    \u001b[0m | \u001b[0m11.51    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 23.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m69       \u001b[0m | \u001b[0m-393.9   \u001b[0m | \u001b[0m111.3    \u001b[0m | \u001b[0m429.1    \u001b[0m | \u001b[0m3.136    \u001b[0m | \u001b[0m5.698    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 174/250 [00:59<00:25,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m70       \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m1.235e+03\u001b[0m | \u001b[0m363.8    \u001b[0m | \u001b[0m3.528    \u001b[0m | \u001b[0m1.76     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 188/250 [00:39<00:13,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m71       \u001b[0m | \u001b[0m-213.5   \u001b[0m | \u001b[0m1.786e+03\u001b[0m | \u001b[0m114.5    \u001b[0m | \u001b[0m1.508    \u001b[0m | \u001b[0m23.54    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:31<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m72       \u001b[0m | \u001b[0m-267.8   \u001b[0m | \u001b[0m187.2    \u001b[0m | \u001b[0m739.9    \u001b[0m | \u001b[0m4.884    \u001b[0m | \u001b[0m26.28    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 171/250 [00:57<00:26,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m73       \u001b[0m | \u001b[0m-267.0   \u001b[0m | \u001b[0m1.449e+03\u001b[0m | \u001b[0m962.7    \u001b[0m | \u001b[0m2.719    \u001b[0m | \u001b[0m26.31    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 229/250 [00:19<00:01, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m74       \u001b[0m | \u001b[0m-216.6   \u001b[0m | \u001b[0m776.3    \u001b[0m | \u001b[0m936.8    \u001b[0m | \u001b[0m1.595    \u001b[0m | \u001b[0m28.26    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 182/250 [00:38<00:14,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m75       \u001b[0m | \u001b[0m-210.9   \u001b[0m | \u001b[0m1.682e+03\u001b[0m | \u001b[0m861.4    \u001b[0m | \u001b[0m1.496    \u001b[0m | \u001b[0m18.3     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:05<00:00, 43.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m76       \u001b[0m | \u001b[0m-307.3   \u001b[0m | \u001b[0m131.1    \u001b[0m | \u001b[0m749.1    \u001b[0m | \u001b[0m1.031    \u001b[0m | \u001b[0m3.46     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 238/250 [00:24<00:01,  9.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m77       \u001b[0m | \u001b[0m-230.8   \u001b[0m | \u001b[0m528.4    \u001b[0m | \u001b[0m887.6    \u001b[0m | \u001b[0m2.454    \u001b[0m | \u001b[0m16.66    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 177/250 [00:56<00:23,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m78       \u001b[0m | \u001b[0m-267.0   \u001b[0m | \u001b[0m1.179e+03\u001b[0m | \u001b[0m302.9    \u001b[0m | \u001b[0m3.289    \u001b[0m | \u001b[0m20.17    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 236/250 [00:30<00:01,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m79       \u001b[0m | \u001b[0m-232.6   \u001b[0m | \u001b[0m666.7    \u001b[0m | \u001b[0m476.8    \u001b[0m | \u001b[0m2.812    \u001b[0m | \u001b[0m28.04    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 184/250 [01:20<00:28,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m80       \u001b[0m | \u001b[0m-268.0   \u001b[0m | \u001b[0m1.216e+03\u001b[0m | \u001b[0m953.4    \u001b[0m | \u001b[0m3.224    \u001b[0m | \u001b[0m15.52    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m81       \u001b[0m | \u001b[0m-365.2   \u001b[0m | \u001b[0m106.7    \u001b[0m | \u001b[0m532.8    \u001b[0m | \u001b[0m4.71     \u001b[0m | \u001b[0m6.753    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:15<00:00, 15.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m82       \u001b[0m | \u001b[0m-263.8   \u001b[0m | \u001b[0m199.0    \u001b[0m | \u001b[0m466.1    \u001b[0m | \u001b[0m2.49     \u001b[0m | \u001b[0m25.86    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:24<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m83       \u001b[0m | \u001b[0m-282.2   \u001b[0m | \u001b[0m150.6    \u001b[0m | \u001b[0m928.1    \u001b[0m | \u001b[0m3.724    \u001b[0m | \u001b[0m27.22    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 172/250 [00:46<00:21,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m84       \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.254e+03\u001b[0m | \u001b[0m830.8    \u001b[0m | \u001b[0m2.342    \u001b[0m | \u001b[0m11.14    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 202/250 [00:30<00:07,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m85       \u001b[0m | \u001b[0m-264.4   \u001b[0m | \u001b[0m840.8    \u001b[0m | \u001b[0m779.3    \u001b[0m | \u001b[0m2.477    \u001b[0m | \u001b[0m8.024    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 153/250 [01:18<00:49,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m86       \u001b[0m | \u001b[0m-269.0   \u001b[0m | \u001b[0m1.882e+03\u001b[0m | \u001b[0m917.2    \u001b[0m | \u001b[0m2.395    \u001b[0m | \u001b[0m19.4     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 228/250 [00:21<00:02, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m87       \u001b[0m | \u001b[0m-234.4   \u001b[0m | \u001b[0m620.3    \u001b[0m | \u001b[0m285.5    \u001b[0m | \u001b[0m2.345    \u001b[0m | \u001b[0m10.49    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 163/250 [01:48<00:57,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m88       \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.776e+03\u001b[0m | \u001b[0m840.1    \u001b[0m | \u001b[0m3.838    \u001b[0m | \u001b[0m28.82    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 247/250 [00:20<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m89       \u001b[0m | \u001b[0m-211.8   \u001b[0m | \u001b[0m902.8    \u001b[0m | \u001b[0m320.5    \u001b[0m | \u001b[0m1.47     \u001b[0m | \u001b[0m9.731    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:19<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m90       \u001b[0m | \u001b[0m-243.5   \u001b[0m | \u001b[0m376.0    \u001b[0m | \u001b[0m183.0    \u001b[0m | \u001b[0m3.412    \u001b[0m | \u001b[0m11.56    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 181/250 [00:54<00:20,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m91       \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.173e+03\u001b[0m | \u001b[0m272.2    \u001b[0m | \u001b[0m3.708    \u001b[0m | \u001b[0m7.25     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 242/250 [00:36<00:01,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m92       \u001b[0m | \u001b[0m-235.8   \u001b[0m | \u001b[0m628.2    \u001b[0m | \u001b[0m767.6    \u001b[0m | \u001b[0m3.239    \u001b[0m | \u001b[0m10.71    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 188/250 [01:25<00:28,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m93       \u001b[0m | \u001b[0m-267.1   \u001b[0m | \u001b[0m1.132e+03\u001b[0m | \u001b[0m724.6    \u001b[0m | \u001b[0m4.649    \u001b[0m | \u001b[0m17.84    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:43<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m94       \u001b[0m | \u001b[0m-249.0   \u001b[0m | \u001b[0m542.1    \u001b[0m | \u001b[0m772.0    \u001b[0m | \u001b[0m4.111    \u001b[0m | \u001b[0m6.812    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 163/250 [01:59<01:03,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m95       \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.659e+03\u001b[0m | \u001b[0m518.4    \u001b[0m | \u001b[0m4.119    \u001b[0m | \u001b[0m7.887    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 233/250 [00:50<00:03,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m96       \u001b[0m | \u001b[0m-241.9   \u001b[0m | \u001b[0m731.9    \u001b[0m | \u001b[0m958.3    \u001b[0m | \u001b[0m3.631    \u001b[0m | \u001b[0m23.41    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 182/250 [00:49<00:18,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m97       \u001b[0m | \u001b[0m-263.0   \u001b[0m | \u001b[0m1.408e+03\u001b[0m | \u001b[0m283.9    \u001b[0m | \u001b[0m2.883    \u001b[0m | \u001b[0m24.46    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 198/250 [00:28<00:07,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m98       \u001b[0m | \u001b[0m-217.9   \u001b[0m | \u001b[0m1.383e+03\u001b[0m | \u001b[0m105.4    \u001b[0m | \u001b[0m1.35     \u001b[0m | \u001b[0m11.06    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 162/250 [01:16<00:41,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m99       \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.894e+03\u001b[0m | \u001b[0m542.1    \u001b[0m | \u001b[0m2.081    \u001b[0m | \u001b[0m11.45    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m100      \u001b[0m | \u001b[0m-241.0   \u001b[0m | \u001b[0m500.2    \u001b[0m | \u001b[0m479.1    \u001b[0m | \u001b[0m1.872    \u001b[0m | \u001b[0m25.53    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 196/250 [01:04<00:17,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m101      \u001b[0m | \u001b[0m-266.6   \u001b[0m | \u001b[0m966.9    \u001b[0m | \u001b[0m351.8    \u001b[0m | \u001b[0m4.732    \u001b[0m | \u001b[0m10.12    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 158/250 [01:50<01:04,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m102      \u001b[0m | \u001b[0m-269.2   \u001b[0m | \u001b[0m1.828e+03\u001b[0m | \u001b[0m139.1    \u001b[0m | \u001b[0m3.828    \u001b[0m | \u001b[0m15.03    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 219/250 [00:18<00:02, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m103      \u001b[0m | \u001b[0m-222.5   \u001b[0m | \u001b[0m944.0    \u001b[0m | \u001b[0m132.7    \u001b[0m | \u001b[0m1.163    \u001b[0m | \u001b[0m10.65    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 164/250 [01:20<00:42,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m104      \u001b[0m | \u001b[0m-268.9   \u001b[0m | \u001b[0m1.9e+03  \u001b[0m | \u001b[0m655.9    \u001b[0m | \u001b[0m2.475    \u001b[0m | \u001b[0m18.75    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:23<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m105      \u001b[0m | \u001b[0m-235.0   \u001b[0m | \u001b[0m491.6    \u001b[0m | \u001b[0m248.6    \u001b[0m | \u001b[0m2.447    \u001b[0m | \u001b[0m26.04    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 191/250 [01:13<00:22,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m106      \u001b[0m | \u001b[0m-267.0   \u001b[0m | \u001b[0m1.068e+03\u001b[0m | \u001b[0m367.2    \u001b[0m | \u001b[0m4.801    \u001b[0m | \u001b[0m24.66    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 212/250 [00:53<00:09,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m107      \u001b[0m | \u001b[0m-266.8   \u001b[0m | \u001b[0m713.7    \u001b[0m | \u001b[0m974.9    \u001b[0m | \u001b[0m4.949    \u001b[0m | \u001b[0m12.85    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 166/250 [00:40<00:20,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m108      \u001b[0m | \u001b[0m-268.2   \u001b[0m | \u001b[0m1.346e+03\u001b[0m | \u001b[0m465.1    \u001b[0m | \u001b[0m2.029    \u001b[0m | \u001b[0m3.397    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 241/250 [00:21<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m109      \u001b[0m | \u001b[0m-223.1   \u001b[0m | \u001b[0m600.9    \u001b[0m | \u001b[0m344.3    \u001b[0m | \u001b[0m2.595    \u001b[0m | \u001b[0m6.362    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 159/250 [01:42<00:58,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m110      \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m1.912e+03\u001b[0m | \u001b[0m192.6    \u001b[0m | \u001b[0m3.501    \u001b[0m | \u001b[0m13.81    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 200/250 [00:59<00:14,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m111      \u001b[0m | \u001b[0m-265.9   \u001b[0m | \u001b[0m904.7    \u001b[0m | \u001b[0m434.8    \u001b[0m | \u001b[0m4.473    \u001b[0m | \u001b[0m9.134    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:18<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m112      \u001b[0m | \u001b[0m-297.2   \u001b[0m | \u001b[0m139.1    \u001b[0m | \u001b[0m926.3    \u001b[0m | \u001b[0m4.458    \u001b[0m | \u001b[0m9.03     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 203/250 [00:22<00:05,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m113      \u001b[0m | \u001b[0m-222.2   \u001b[0m | \u001b[0m1.095e+03\u001b[0m | \u001b[0m198.2    \u001b[0m | \u001b[0m1.374    \u001b[0m | \u001b[0m25.29    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:01<00:14,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m114      \u001b[0m | \u001b[0m-267.2   \u001b[0m | \u001b[0m879.5    \u001b[0m | \u001b[0m695.5    \u001b[0m | \u001b[0m4.773    \u001b[0m | \u001b[0m8.109    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:20<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m115      \u001b[0m | \u001b[0m-342.0   \u001b[0m | \u001b[0m125.0    \u001b[0m | \u001b[0m121.7    \u001b[0m | \u001b[0m3.838    \u001b[0m | \u001b[0m27.81    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 192/250 [00:54<00:16,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m116      \u001b[0m | \u001b[0m-266.4   \u001b[0m | \u001b[0m987.9    \u001b[0m | \u001b[0m437.6    \u001b[0m | \u001b[0m3.171    \u001b[0m | \u001b[0m25.91    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 171/250 [01:19<00:36,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m117      \u001b[0m | \u001b[0m-267.1   \u001b[0m | \u001b[0m1.339e+03\u001b[0m | \u001b[0m309.7    \u001b[0m | \u001b[0m4.098    \u001b[0m | \u001b[0m4.904    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:12<00:00, 19.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m118      \u001b[0m | \u001b[0m-238.6   \u001b[0m | \u001b[0m414.6    \u001b[0m | \u001b[0m651.4    \u001b[0m | \u001b[0m1.955    \u001b[0m | \u001b[0m21.44    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 213/250 [00:43<00:07,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m119      \u001b[0m | \u001b[0m-266.4   \u001b[0m | \u001b[0m764.1    \u001b[0m | \u001b[0m349.7    \u001b[0m | \u001b[0m4.996    \u001b[0m | \u001b[0m2.178    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 172/250 [01:20<00:36,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m120      \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.327e+03\u001b[0m | \u001b[0m134.8    \u001b[0m | \u001b[0m4.041    \u001b[0m | \u001b[0m7.673    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:24<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m121      \u001b[0m | \u001b[0m-262.0   \u001b[0m | \u001b[0m270.7    \u001b[0m | \u001b[0m683.6    \u001b[0m | \u001b[0m3.93     \u001b[0m | \u001b[0m20.66    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m122      \u001b[0m | \u001b[0m-281.6   \u001b[0m | \u001b[0m198.6    \u001b[0m | \u001b[0m364.9    \u001b[0m | \u001b[0m2.804    \u001b[0m | \u001b[0m9.326    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 165/250 [01:23<00:42,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m123      \u001b[0m | \u001b[0m-268.9   \u001b[0m | \u001b[0m1.64e+03 \u001b[0m | \u001b[0m218.0    \u001b[0m | \u001b[0m3.449    \u001b[0m | \u001b[0m29.66    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 181/250 [00:39<00:15,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m124      \u001b[0m | \u001b[0m-215.3   \u001b[0m | \u001b[0m1.815e+03\u001b[0m | \u001b[0m299.9    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m29.44    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 156/250 [01:08<00:41,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m125      \u001b[0m | \u001b[0m-268.8   \u001b[0m | \u001b[0m1.777e+03\u001b[0m | \u001b[0m927.5    \u001b[0m | \u001b[0m2.662    \u001b[0m | \u001b[0m22.59    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 244/250 [00:32<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m126      \u001b[0m | \u001b[0m-246.5   \u001b[0m | \u001b[0m504.4    \u001b[0m | \u001b[0m453.1    \u001b[0m | \u001b[0m4.406    \u001b[0m | \u001b[0m4.701    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 161/250 [01:07<00:37,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m127      \u001b[0m | \u001b[0m-269.1   \u001b[0m | \u001b[0m1.798e+03\u001b[0m | \u001b[0m546.9    \u001b[0m | \u001b[0m2.704    \u001b[0m | \u001b[0m9.864    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 153/250 [02:18<01:27,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m128      \u001b[0m | \u001b[0m-269.6   \u001b[0m | \u001b[0m1.842e+03\u001b[0m | \u001b[0m565.9    \u001b[0m | \u001b[0m4.216    \u001b[0m | \u001b[0m25.87    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 158/250 [01:05<00:38,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m129      \u001b[0m | \u001b[0m-269.0   \u001b[0m | \u001b[0m1.853e+03\u001b[0m | \u001b[0m373.0    \u001b[0m | \u001b[0m2.359    \u001b[0m | \u001b[0m18.26    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 189/250 [00:37<00:12,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m130      \u001b[0m | \u001b[0m-267.8   \u001b[0m | \u001b[0m938.5    \u001b[0m | \u001b[0m939.6    \u001b[0m | \u001b[0m2.59     \u001b[0m | \u001b[0m14.86    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 173/250 [01:24<00:37,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m131      \u001b[0m | \u001b[0m-268.0   \u001b[0m | \u001b[0m1.273e+03\u001b[0m | \u001b[0m464.3    \u001b[0m | \u001b[0m4.97     \u001b[0m | \u001b[0m3.867    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:11<00:00, 20.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m132      \u001b[0m | \u001b[0m-232.5   \u001b[0m | \u001b[0m519.1    \u001b[0m | \u001b[0m390.4    \u001b[0m | \u001b[0m1.591    \u001b[0m | \u001b[0m9.242    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 190/250 [00:36<00:11,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m133      \u001b[0m | \u001b[0m-216.1   \u001b[0m | \u001b[0m1.581e+03\u001b[0m | \u001b[0m570.6    \u001b[0m | \u001b[0m1.136    \u001b[0m | \u001b[0m29.5     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 178/250 [01:06<00:26,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m134      \u001b[0m | \u001b[0m-267.1   \u001b[0m | \u001b[0m1.27e+03 \u001b[0m | \u001b[0m153.0    \u001b[0m | \u001b[0m3.645    \u001b[0m | \u001b[0m11.97    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:26<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m135      \u001b[0m | \u001b[0m-244.1   \u001b[0m | \u001b[0m357.8    \u001b[0m | \u001b[0m607.3    \u001b[0m | \u001b[0m3.908    \u001b[0m | \u001b[0m20.46    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:40<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m136      \u001b[0m | \u001b[0m-222.4   \u001b[0m | \u001b[0m570.3    \u001b[0m | \u001b[0m572.4    \u001b[0m | \u001b[0m3.151    \u001b[0m | \u001b[0m21.79    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 205/250 [00:43<00:09,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m137      \u001b[0m | \u001b[0m-267.2   \u001b[0m | \u001b[0m783.7    \u001b[0m | \u001b[0m818.0    \u001b[0m | \u001b[0m3.512    \u001b[0m | \u001b[0m2.112    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 178/250 [01:00<00:24,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m138      \u001b[0m | \u001b[0m-268.0   \u001b[0m | \u001b[0m1.138e+03\u001b[0m | \u001b[0m875.7    \u001b[0m | \u001b[0m3.27     \u001b[0m | \u001b[0m6.099    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 202/250 [00:24<00:05,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m139      \u001b[0m | \u001b[0m-220.8   \u001b[0m | \u001b[0m1.07e+03 \u001b[0m | \u001b[0m781.3    \u001b[0m | \u001b[0m1.44     \u001b[0m | \u001b[0m24.7     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m140      \u001b[0m | \u001b[0m-238.5   \u001b[0m | \u001b[0m418.2    \u001b[0m | \u001b[0m580.7    \u001b[0m | \u001b[0m2.543    \u001b[0m | \u001b[0m8.21     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 183/250 [01:25<00:31,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m141      \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.33e+03 \u001b[0m | \u001b[0m133.7    \u001b[0m | \u001b[0m4.04     \u001b[0m | \u001b[0m16.28    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 187/250 [00:37<00:12,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m142      \u001b[0m | \u001b[0m-215.8   \u001b[0m | \u001b[0m1.764e+03\u001b[0m | \u001b[0m568.6    \u001b[0m | \u001b[0m1.14     \u001b[0m | \u001b[0m5.164    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 162/250 [00:58<00:31,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m143      \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.612e+03\u001b[0m | \u001b[0m542.8    \u001b[0m | \u001b[0m2.768    \u001b[0m | \u001b[0m10.23    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 220/250 [00:29<00:04,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m144      \u001b[0m | \u001b[0m-236.7   \u001b[0m | \u001b[0m640.6    \u001b[0m | \u001b[0m969.3    \u001b[0m | \u001b[0m2.732    \u001b[0m | \u001b[0m26.64    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 172/250 [01:47<00:48,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m145      \u001b[0m | \u001b[0m-268.2   \u001b[0m | \u001b[0m1.332e+03\u001b[0m | \u001b[0m872.6    \u001b[0m | \u001b[0m4.41     \u001b[0m | \u001b[0m28.73    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 169/250 [01:28<00:42,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m146      \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m1.426e+03\u001b[0m | \u001b[0m824.9    \u001b[0m | \u001b[0m3.933    \u001b[0m | \u001b[0m18.55    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [00:37<00:09,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m147      \u001b[0m | \u001b[0m-209.5   \u001b[0m | \u001b[0m1.463e+03\u001b[0m | \u001b[0m744.2    \u001b[0m | \u001b[0m1.164    \u001b[0m | \u001b[0m15.97    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 212/250 [01:10<00:12,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m148      \u001b[0m | \u001b[0m-237.7   \u001b[0m | \u001b[0m1.606e+03\u001b[0m | \u001b[0m318.7    \u001b[0m | \u001b[0m2.861    \u001b[0m | \u001b[0m13.61    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 199/250 [00:40<00:10,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m149      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m865.3    \u001b[0m | \u001b[0m209.7    \u001b[0m | \u001b[0m3.103    \u001b[0m | \u001b[0m13.94    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 195/250 [00:25<00:07,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m150      \u001b[0m | \u001b[0m-230.2   \u001b[0m | \u001b[0m1.36e+03 \u001b[0m | \u001b[0m594.5    \u001b[0m | \u001b[0m1.11     \u001b[0m | \u001b[0m1.926    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 169/250 [01:47<00:51,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m151      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.433e+03\u001b[0m | \u001b[0m736.8    \u001b[0m | \u001b[0m4.84     \u001b[0m | \u001b[0m26.42    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 189/250 [00:36<00:11,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m152      \u001b[0m | \u001b[0m-266.5   \u001b[0m | \u001b[0m989.3    \u001b[0m | \u001b[0m663.3    \u001b[0m | \u001b[0m2.829    \u001b[0m | \u001b[0m7.465    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 205/250 [00:37<00:08,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m153      \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m815.7    \u001b[0m | \u001b[0m193.5    \u001b[0m | \u001b[0m3.666    \u001b[0m | \u001b[0m6.569    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 217/250 [00:22<00:03,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m154      \u001b[0m | \u001b[0m-215.2   \u001b[0m | \u001b[0m1.003e+03\u001b[0m | \u001b[0m970.7    \u001b[0m | \u001b[0m1.127    \u001b[0m | \u001b[0m5.4      \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 221/250 [00:50<00:06,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m155      \u001b[0m | \u001b[0m-266.9   \u001b[0m | \u001b[0m667.3    \u001b[0m | \u001b[0m947.6    \u001b[0m | \u001b[0m4.635    \u001b[0m | \u001b[0m5.698    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 161/250 [02:17<01:15,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m156      \u001b[0m | \u001b[0m-269.1   \u001b[0m | \u001b[0m1.964e+03\u001b[0m | \u001b[0m775.7    \u001b[0m | \u001b[0m3.16     \u001b[0m | \u001b[0m28.02    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 160/250 [01:55<01:05,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m157      \u001b[0m | \u001b[0m-268.7   \u001b[0m | \u001b[0m1.773e+03\u001b[0m | \u001b[0m452.2    \u001b[0m | \u001b[0m3.625    \u001b[0m | \u001b[0m19.77    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 213/250 [00:23<00:04,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m158      \u001b[0m | \u001b[0m-267.9   \u001b[0m | \u001b[0m721.2    \u001b[0m | \u001b[0m261.5    \u001b[0m | \u001b[0m2.867    \u001b[0m | \u001b[0m8.635    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 234/250 [00:35<00:02,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m159      \u001b[0m | \u001b[0m-229.1   \u001b[0m | \u001b[0m774.6    \u001b[0m | \u001b[0m958.7    \u001b[0m | \u001b[0m2.845    \u001b[0m | \u001b[0m20.86    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 215/250 [00:44<00:07,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m160      \u001b[0m | \u001b[0m-266.5   \u001b[0m | \u001b[0m738.8    \u001b[0m | \u001b[0m996.3    \u001b[0m | \u001b[0m3.635    \u001b[0m | \u001b[0m6.684    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:34<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m161      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m286.5    \u001b[0m | \u001b[0m948.9    \u001b[0m | \u001b[0m4.779    \u001b[0m | \u001b[0m19.02    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:26<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m162      \u001b[0m | \u001b[0m-303.9   \u001b[0m | \u001b[0m132.3    \u001b[0m | \u001b[0m303.0    \u001b[0m | \u001b[0m4.205    \u001b[0m | \u001b[0m26.39    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 192/250 [00:32<00:09,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m163      \u001b[0m | \u001b[0m-267.8   \u001b[0m | \u001b[0m962.6    \u001b[0m | \u001b[0m429.0    \u001b[0m | \u001b[0m2.097    \u001b[0m | \u001b[0m4.392    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:25<00:00,  9.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m164      \u001b[0m | \u001b[0m-258.7   \u001b[0m | \u001b[0m319.9    \u001b[0m | \u001b[0m957.3    \u001b[0m | \u001b[0m4.235    \u001b[0m | \u001b[0m5.779    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:46<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m165      \u001b[0m | \u001b[0m-231.2   \u001b[0m | \u001b[0m493.4    \u001b[0m | \u001b[0m690.0    \u001b[0m | \u001b[0m4.059    \u001b[0m | \u001b[0m24.5     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:12<00:00, 20.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m166      \u001b[0m | \u001b[0m-238.4   \u001b[0m | \u001b[0m410.3    \u001b[0m | \u001b[0m985.7    \u001b[0m | \u001b[0m1.911    \u001b[0m | \u001b[0m18.09    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 183/250 [01:11<00:26,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m167      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.216e+03\u001b[0m | \u001b[0m970.6    \u001b[0m | \u001b[0m3.631    \u001b[0m | \u001b[0m17.96    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [00:22<00:05,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m168      \u001b[0m | \u001b[0m-233.1   \u001b[0m | \u001b[0m1.086e+03\u001b[0m | \u001b[0m788.2    \u001b[0m | \u001b[0m1.424    \u001b[0m | \u001b[0m1.061    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 160/250 [01:30<00:50,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m169      \u001b[0m | \u001b[0m-269.4   \u001b[0m | \u001b[0m1.91e+03 \u001b[0m | \u001b[0m548.8    \u001b[0m | \u001b[0m2.313    \u001b[0m | \u001b[0m11.67    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 168/250 [02:18<01:07,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m170      \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.627e+03\u001b[0m | \u001b[0m444.1    \u001b[0m | \u001b[0m4.081    \u001b[0m | \u001b[0m13.77    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 177/250 [01:03<00:26,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m171      \u001b[0m | \u001b[0m-255.6   \u001b[0m | \u001b[0m1.704e+03\u001b[0m | \u001b[0m168.6    \u001b[0m | \u001b[0m2.925    \u001b[0m | \u001b[0m14.54    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 236/250 [00:51<00:03,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m172      \u001b[0m | \u001b[0m-266.9   \u001b[0m | \u001b[0m602.2    \u001b[0m | \u001b[0m949.3    \u001b[0m | \u001b[0m4.62     \u001b[0m | \u001b[0m13.86    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m173      \u001b[0m | \u001b[0m-259.0   \u001b[0m | \u001b[0m284.6    \u001b[0m | \u001b[0m286.1    \u001b[0m | \u001b[0m2.086    \u001b[0m | \u001b[0m15.04    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m174      \u001b[0m | \u001b[0m-216.4   \u001b[0m | \u001b[0m742.9    \u001b[0m | \u001b[0m796.7    \u001b[0m | \u001b[0m2.904    \u001b[0m | \u001b[0m26.24    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 161/250 [02:03<01:08,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m175      \u001b[0m | \u001b[0m-269.6   \u001b[0m | \u001b[0m1.992e+03\u001b[0m | \u001b[0m297.9    \u001b[0m | \u001b[0m3.447    \u001b[0m | \u001b[0m25.58    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 159/250 [01:39<00:57,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m176      \u001b[0m | \u001b[0m-268.8   \u001b[0m | \u001b[0m1.896e+03\u001b[0m | \u001b[0m361.1    \u001b[0m | \u001b[0m3.908    \u001b[0m | \u001b[0m1.435    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 155/250 [01:34<00:57,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m177      \u001b[0m | \u001b[0m-270.0   \u001b[0m | \u001b[0m1.77e+03 \u001b[0m | \u001b[0m157.5    \u001b[0m | \u001b[0m3.934    \u001b[0m | \u001b[0m29.84    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 190/250 [00:56<00:17,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m178      \u001b[0m | \u001b[0m-266.6   \u001b[0m | \u001b[0m1.052e+03\u001b[0m | \u001b[0m288.4    \u001b[0m | \u001b[0m3.379    \u001b[0m | \u001b[0m19.1     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 171/250 [01:25<00:39,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m179      \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.369e+03\u001b[0m | \u001b[0m255.4    \u001b[0m | \u001b[0m4.595    \u001b[0m | \u001b[0m19.01    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:06<00:00, 39.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m180      \u001b[0m | \u001b[0m-254.2   \u001b[0m | \u001b[0m182.8    \u001b[0m | \u001b[0m715.6    \u001b[0m | \u001b[0m1.784    \u001b[0m | \u001b[0m1.793    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 178/250 [01:23<00:33,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m181      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.147e+03\u001b[0m | \u001b[0m832.0    \u001b[0m | \u001b[0m4.44     \u001b[0m | \u001b[0m4.002    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 172/250 [00:52<00:24,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m182      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.36e+03 \u001b[0m | \u001b[0m739.1    \u001b[0m | \u001b[0m2.178    \u001b[0m | \u001b[0m29.17    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 231/250 [00:37<00:03,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m183      \u001b[0m | \u001b[0m-262.7   \u001b[0m | \u001b[0m629.5    \u001b[0m | \u001b[0m163.0    \u001b[0m | \u001b[0m3.077    \u001b[0m | \u001b[0m21.14    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:39<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m184      \u001b[0m | \u001b[0m-232.3   \u001b[0m | \u001b[0m564.9    \u001b[0m | \u001b[0m404.7    \u001b[0m | \u001b[0m3.255    \u001b[0m | \u001b[0m26.71    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 170/250 [00:49<00:23,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m185      \u001b[0m | \u001b[0m-263.0   \u001b[0m | \u001b[0m1.52e+03 \u001b[0m | \u001b[0m288.6    \u001b[0m | \u001b[0m2.007    \u001b[0m | \u001b[0m16.19    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 167/250 [01:37<00:48,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m186      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.561e+03\u001b[0m | \u001b[0m656.9    \u001b[0m | \u001b[0m3.005    \u001b[0m | \u001b[0m18.32    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 165/250 [02:01<01:02,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m187      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.537e+03\u001b[0m | \u001b[0m583.4    \u001b[0m | \u001b[0m4.591    \u001b[0m | \u001b[0m28.46    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 176/250 [00:41<00:17,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m188      \u001b[0m | \u001b[0m-215.1   \u001b[0m | \u001b[0m1.839e+03\u001b[0m | \u001b[0m779.1    \u001b[0m | \u001b[0m1.985    \u001b[0m | \u001b[0m12.17    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 227/250 [00:27<00:02,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m189      \u001b[0m | \u001b[0m-238.7   \u001b[0m | \u001b[0m632.0    \u001b[0m | \u001b[0m691.9    \u001b[0m | \u001b[0m2.297    \u001b[0m | \u001b[0m22.88    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:28<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m190      \u001b[0m | \u001b[0m-250.9   \u001b[0m | \u001b[0m315.7    \u001b[0m | \u001b[0m797.8    \u001b[0m | \u001b[0m3.344    \u001b[0m | \u001b[0m25.23    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 192/250 [00:54<00:16,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m191      \u001b[0m | \u001b[0m-266.2   \u001b[0m | \u001b[0m918.7    \u001b[0m | \u001b[0m662.5    \u001b[0m | \u001b[0m3.218    \u001b[0m | \u001b[0m29.29    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 184/250 [00:35<00:12,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m192      \u001b[0m | \u001b[0m-216.5   \u001b[0m | \u001b[0m1.535e+03\u001b[0m | \u001b[0m590.3    \u001b[0m | \u001b[0m1.696    \u001b[0m | \u001b[0m27.22    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 248/250 [00:37<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m193      \u001b[0m | \u001b[0m-244.0   \u001b[0m | \u001b[0m491.1    \u001b[0m | \u001b[0m685.0    \u001b[0m | \u001b[0m4.746    \u001b[0m | \u001b[0m7.484    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 235/250 [00:44<00:02,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m194      \u001b[0m | \u001b[0m-269.6   \u001b[0m | \u001b[0m529.3    \u001b[0m | \u001b[0m866.6    \u001b[0m | \u001b[0m4.311    \u001b[0m | \u001b[0m11.2     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:51<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m195      \u001b[0m | \u001b[0m-244.5   \u001b[0m | \u001b[0m603.7    \u001b[0m | \u001b[0m214.6    \u001b[0m | \u001b[0m4.952    \u001b[0m | \u001b[0m25.22    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 166/250 [00:35<00:17,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m196      \u001b[0m | \u001b[0m-236.5   \u001b[0m | \u001b[0m1.809e+03\u001b[0m | \u001b[0m562.3    \u001b[0m | \u001b[0m1.458    \u001b[0m | \u001b[0m2.525    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 216/250 [01:05<00:10,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m197      \u001b[0m | \u001b[0m-266.4   \u001b[0m | \u001b[0m728.1    \u001b[0m | \u001b[0m928.3    \u001b[0m | \u001b[0m4.79     \u001b[0m | \u001b[0m25.39    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m198      \u001b[0m | \u001b[0m-240.4   \u001b[0m | \u001b[0m401.5    \u001b[0m | \u001b[0m477.9    \u001b[0m | \u001b[0m1.985    \u001b[0m | \u001b[0m6.955    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 183/250 [00:49<00:18,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m199      \u001b[0m | \u001b[0m-261.5   \u001b[0m | \u001b[0m1.401e+03\u001b[0m | \u001b[0m537.5    \u001b[0m | \u001b[0m2.3      \u001b[0m | \u001b[0m3.906    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 185/250 [00:38<00:13,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m200      \u001b[0m | \u001b[0m-267.7   \u001b[0m | \u001b[0m1.135e+03\u001b[0m | \u001b[0m412.3    \u001b[0m | \u001b[0m2.564    \u001b[0m | \u001b[0m10.0     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 66%|██████▌   | 165/250 [01:59<01:01,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m201      \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.541e+03\u001b[0m | \u001b[0m603.0    \u001b[0m | \u001b[0m4.887    \u001b[0m | \u001b[0m29.96    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 69%|██████▉   | 173/250 [01:12<00:32,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m202      \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m1.421e+03\u001b[0m | \u001b[0m358.8    \u001b[0m | \u001b[0m3.413    \u001b[0m | \u001b[0m27.63    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 68%|██████▊   | 169/250 [01:11<00:34,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m203      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.432e+03\u001b[0m | \u001b[0m360.0    \u001b[0m | \u001b[0m3.853    \u001b[0m | \u001b[0m13.63    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 86%|████████▌ | 214/250 [01:08<00:11,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m204      \u001b[0m | \u001b[0m-245.5   \u001b[0m | \u001b[0m1.461e+03\u001b[0m | \u001b[0m742.1    \u001b[0m | \u001b[0m2.362    \u001b[0m | \u001b[0m20.74    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 63%|██████▎   | 158/250 [01:10<00:40,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m205      \u001b[0m | \u001b[0m-268.9   \u001b[0m | \u001b[0m1.864e+03\u001b[0m | \u001b[0m624.6    \u001b[0m | \u001b[0m2.434    \u001b[0m | \u001b[0m22.0     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 74%|███████▍  | 186/250 [00:40<00:13,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m206      \u001b[0m | \u001b[0m-214.8   \u001b[0m | \u001b[0m1.684e+03\u001b[0m | \u001b[0m862.1    \u001b[0m | \u001b[0m1.129    \u001b[0m | \u001b[0m13.46    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 65%|██████▌   | 163/250 [00:57<00:30,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m207      \u001b[0m | \u001b[0m-267.9   \u001b[0m | \u001b[0m1.564e+03\u001b[0m | \u001b[0m618.0    \u001b[0m | \u001b[0m2.752    \u001b[0m | \u001b[0m15.6     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 74%|███████▍  | 185/250 [00:48<00:17,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m208      \u001b[0m | \u001b[0m-217.3   \u001b[0m | \u001b[0m1.874e+03\u001b[0m | \u001b[0m625.5    \u001b[0m | \u001b[0m1.383    \u001b[0m | \u001b[0m18.36    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 72%|███████▏  | 180/250 [00:37<00:14,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m209      \u001b[0m | \u001b[0m-216.6   \u001b[0m | \u001b[0m1.677e+03\u001b[0m | \u001b[0m860.3    \u001b[0m | \u001b[0m1.582    \u001b[0m | \u001b[0m12.63    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 66%|██████▌   | 165/250 [02:26<01:15,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m210      \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.682e+03\u001b[0m | \u001b[0m866.9    \u001b[0m | \u001b[0m4.844    \u001b[0m | \u001b[0m15.67    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 67%|██████▋   | 168/250 [01:16<00:37,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m211      \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m1.462e+03\u001b[0m | \u001b[0m748.5    \u001b[0m | \u001b[0m3.316    \u001b[0m | \u001b[0m13.04    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 73%|███████▎  | 182/250 [00:33<00:12,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m212      \u001b[0m | \u001b[0m-222.9   \u001b[0m | \u001b[0m1.557e+03\u001b[0m | \u001b[0m612.7    \u001b[0m | \u001b[0m1.748    \u001b[0m | \u001b[0m22.58    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 65%|██████▍   | 162/250 [01:03<00:34,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m213      \u001b[0m | \u001b[0m-262.6   \u001b[0m | \u001b[0m1.789e+03\u001b[0m | \u001b[0m117.6    \u001b[0m | \u001b[0m2.555    \u001b[0m | \u001b[0m26.47    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 90%|█████████ | 226/250 [00:14<00:01, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m214      \u001b[0m | \u001b[0m-235.0   \u001b[0m | \u001b[0m665.2    \u001b[0m | \u001b[0m669.6    \u001b[0m | \u001b[0m1.782    \u001b[0m | \u001b[0m12.44    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 67%|██████▋   | 167/250 [01:50<00:55,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m215      \u001b[0m | \u001b[0m-268.0   \u001b[0m | \u001b[0m1.682e+03\u001b[0m | \u001b[0m860.5    \u001b[0m | \u001b[0m3.398    \u001b[0m | \u001b[0m14.87    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 91%|█████████ | 228/250 [00:48<00:04,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m216      \u001b[0m | \u001b[0m-233.0   \u001b[0m | \u001b[0m1.159e+03\u001b[0m | \u001b[0m242.9    \u001b[0m | \u001b[0m2.035    \u001b[0m | \u001b[0m17.04    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 86%|████████▌ | 215/250 [00:31<00:05,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m217      \u001b[0m | \u001b[0m-267.5   \u001b[0m | \u001b[0m790.7    \u001b[0m | \u001b[0m440.7    \u001b[0m | \u001b[0m2.984    \u001b[0m | \u001b[0m17.65    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 63%|██████▎   | 158/250 [01:20<00:46,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m218      \u001b[0m | \u001b[0m-268.8   \u001b[0m | \u001b[0m1.873e+03\u001b[0m | \u001b[0m622.5    \u001b[0m | \u001b[0m2.335    \u001b[0m | \u001b[0m16.51    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 161/250 [01:51<01:01,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m219      \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.839e+03\u001b[0m | \u001b[0m779.8    \u001b[0m | \u001b[0m3.068    \u001b[0m | \u001b[0m13.92    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 69%|██████▉   | 172/250 [01:02<00:28,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m220      \u001b[0m | \u001b[0m-268.7   \u001b[0m | \u001b[0m1.391e+03\u001b[0m | \u001b[0m264.6    \u001b[0m | \u001b[0m3.32     \u001b[0m | \u001b[0m1.64     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 84%|████████▍ | 211/250 [00:14<00:02, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m221      \u001b[0m | \u001b[0m-241.9   \u001b[0m | \u001b[0m849.1    \u001b[0m | \u001b[0m246.8    \u001b[0m | \u001b[0m1.336    \u001b[0m | \u001b[0m1.337    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:10<00:00, 23.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m222      \u001b[0m | \u001b[0m-239.6   \u001b[0m | \u001b[0m445.3    \u001b[0m | \u001b[0m528.5    \u001b[0m | \u001b[0m1.694    \u001b[0m | \u001b[0m16.37    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 99%|█████████▉| 247/250 [00:11<00:00, 21.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m223      \u001b[0m | \u001b[0m-230.5   \u001b[0m | \u001b[0m579.8    \u001b[0m | \u001b[0m300.7    \u001b[0m | \u001b[0m1.606    \u001b[0m | \u001b[0m7.466    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 70%|██████▉   | 174/250 [00:41<00:18,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m224      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.203e+03\u001b[0m | \u001b[0m614.8    \u001b[0m | \u001b[0m2.423    \u001b[0m | \u001b[0m9.944    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 71%|███████   | 178/250 [01:24<00:34,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m225      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.301e+03\u001b[0m | \u001b[0m902.8    \u001b[0m | \u001b[0m3.572    \u001b[0m | \u001b[0m29.38    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 66%|██████▌   | 164/250 [01:55<01:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m226      \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.638e+03\u001b[0m | \u001b[0m562.2    \u001b[0m | \u001b[0m4.246    \u001b[0m | \u001b[0m12.46    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 77%|███████▋  | 193/250 [01:07<00:19,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m227      \u001b[0m | \u001b[0m-267.0   \u001b[0m | \u001b[0m952.0    \u001b[0m | \u001b[0m664.3    \u001b[0m | \u001b[0m4.28     \u001b[0m | \u001b[0m13.76    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:31<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m228      \u001b[0m | \u001b[0m-262.4   \u001b[0m | \u001b[0m228.4    \u001b[0m | \u001b[0m335.1    \u001b[0m | \u001b[0m4.215    \u001b[0m | \u001b[0m29.9     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 68%|██████▊   | 169/250 [00:37<00:18,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m229      \u001b[0m | \u001b[0m-235.1   \u001b[0m | \u001b[0m1.935e+03\u001b[0m | \u001b[0m333.4    \u001b[0m | \u001b[0m1.211    \u001b[0m | \u001b[0m1.262    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 161/250 [02:08<01:10,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m230      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.735e+03\u001b[0m | \u001b[0m885.3    \u001b[0m | \u001b[0m4.816    \u001b[0m | \u001b[0m3.302    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 75%|███████▌  | 188/250 [00:30<00:10,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m231      \u001b[0m | \u001b[0m-222.7   \u001b[0m | \u001b[0m1.293e+03\u001b[0m | \u001b[0m943.8    \u001b[0m | \u001b[0m1.014    \u001b[0m | \u001b[0m24.33    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:32<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m232      \u001b[0m | \u001b[0m-259.9   \u001b[0m | \u001b[0m265.4    \u001b[0m | \u001b[0m782.5    \u001b[0m | \u001b[0m4.043    \u001b[0m | \u001b[0m23.24    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:23<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m233      \u001b[0m | \u001b[0m-239.4   \u001b[0m | \u001b[0m338.7    \u001b[0m | \u001b[0m214.7    \u001b[0m | \u001b[0m3.848    \u001b[0m | \u001b[0m19.04    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 83%|████████▎ | 207/250 [00:36<00:07,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m234      \u001b[0m | \u001b[0m-270.6   \u001b[0m | \u001b[0m596.4    \u001b[0m | \u001b[0m461.9    \u001b[0m | \u001b[0m4.457    \u001b[0m | \u001b[0m8.807    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:11<00:00, 20.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m235      \u001b[0m | \u001b[0m-355.8   \u001b[0m | \u001b[0m117.9    \u001b[0m | \u001b[0m531.1    \u001b[0m | \u001b[0m2.698    \u001b[0m | \u001b[0m17.18    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m236      \u001b[0m | \u001b[0m-269.0   \u001b[0m | \u001b[0m1.854e+03\u001b[0m | \u001b[0m234.5    \u001b[0m | \u001b[0m3.337    \u001b[0m | \u001b[0m22.79    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:12<00:00, 20.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m237      \u001b[0m | \u001b[0m-240.7   \u001b[0m | \u001b[0m434.3    \u001b[0m | \u001b[0m419.8    \u001b[0m | \u001b[0m1.564    \u001b[0m | \u001b[0m21.72    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:10<00:00, 23.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m238      \u001b[0m | \u001b[0m-241.9   \u001b[0m | \u001b[0m265.0    \u001b[0m | \u001b[0m164.3    \u001b[0m | \u001b[0m2.144    \u001b[0m | \u001b[0m6.27     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 95%|█████████▌| 238/250 [00:26<00:01,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m239      \u001b[0m | \u001b[0m-231.8   \u001b[0m | \u001b[0m606.3    \u001b[0m | \u001b[0m847.2    \u001b[0m | \u001b[0m2.618    \u001b[0m | \u001b[0m17.43    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 73%|███████▎  | 182/250 [00:49<00:18,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m240      \u001b[0m | \u001b[0m-266.3   \u001b[0m | \u001b[0m1.128e+03\u001b[0m | \u001b[0m185.3    \u001b[0m | \u001b[0m3.617    \u001b[0m | \u001b[0m6.971    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 69%|██████▉   | 173/250 [01:06<00:29,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m241      \u001b[0m | \u001b[0m-268.0   \u001b[0m | \u001b[0m1.261e+03\u001b[0m | \u001b[0m875.2    \u001b[0m | \u001b[0m3.584    \u001b[0m | \u001b[0m4.289    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 160/250 [01:11<00:40,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m242      \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.747e+03\u001b[0m | \u001b[0m481.4    \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m12.81    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 61%|██████    | 152/250 [01:58<01:16,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m243      \u001b[0m | \u001b[0m-268.9   \u001b[0m | \u001b[0m1.998e+03\u001b[0m | \u001b[0m821.8    \u001b[0m | \u001b[0m3.71     \u001b[0m | \u001b[0m15.3     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 66%|██████▋   | 166/250 [01:32<00:46,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m244      \u001b[0m | \u001b[0m-268.9   \u001b[0m | \u001b[0m1.541e+03\u001b[0m | \u001b[0m189.6    \u001b[0m | \u001b[0m4.888    \u001b[0m | \u001b[0m6.427    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:19<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m245      \u001b[0m | \u001b[0m-234.4   \u001b[0m | \u001b[0m432.8    \u001b[0m | \u001b[0m359.9    \u001b[0m | \u001b[0m2.316    \u001b[0m | \u001b[0m17.58    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:42<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m246      \u001b[0m | \u001b[0m-242.2   \u001b[0m | \u001b[0m430.9    \u001b[0m | \u001b[0m666.8    \u001b[0m | \u001b[0m4.406    \u001b[0m | \u001b[0m27.41    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 70%|███████   | 176/250 [00:56<00:23,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m247      \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m1.217e+03\u001b[0m | \u001b[0m177.8    \u001b[0m | \u001b[0m3.432    \u001b[0m | \u001b[0m16.78    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:08<00:00, 30.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m248      \u001b[0m | \u001b[0m-245.7   \u001b[0m | \u001b[0m329.8    \u001b[0m | \u001b[0m744.3    \u001b[0m | \u001b[0m1.975    \u001b[0m | \u001b[0m3.832    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 99%|█████████▉| 248/250 [00:16<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m249      \u001b[0m | \u001b[0m-224.9   \u001b[0m | \u001b[0m652.7    \u001b[0m | \u001b[0m910.3    \u001b[0m | \u001b[0m1.905    \u001b[0m | \u001b[0m16.22    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 71%|███████   | 178/250 [00:39<00:15,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m250      \u001b[0m | \u001b[0m-213.2   \u001b[0m | \u001b[0m1.88e+03 \u001b[0m | \u001b[0m318.5    \u001b[0m | \u001b[0m1.665    \u001b[0m | \u001b[0m10.56    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 72%|███████▏  | 181/250 [00:45<00:17,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m251      \u001b[0m | \u001b[0m-268.0   \u001b[0m | \u001b[0m1.171e+03\u001b[0m | \u001b[0m712.7    \u001b[0m | \u001b[0m2.503    \u001b[0m | \u001b[0m29.37    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 160/250 [01:19<00:44,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m252      \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.915e+03\u001b[0m | \u001b[0m836.2    \u001b[0m | \u001b[0m2.212    \u001b[0m | \u001b[0m19.5     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:39<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m253      \u001b[0m | \u001b[0m-263.7   \u001b[0m | \u001b[0m304.6    \u001b[0m | \u001b[0m914.6    \u001b[0m | \u001b[0m4.027    \u001b[0m | \u001b[0m23.54    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 67%|██████▋   | 168/250 [01:17<00:37,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m254      \u001b[0m | \u001b[0m-268.8   \u001b[0m | \u001b[0m1.569e+03\u001b[0m | \u001b[0m114.0    \u001b[0m | \u001b[0m3.868    \u001b[0m | \u001b[0m12.41    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 87%|████████▋ | 218/250 [00:24<00:03,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m255      \u001b[0m | \u001b[0m-216.7   \u001b[0m | \u001b[0m974.4    \u001b[0m | \u001b[0m847.9    \u001b[0m | \u001b[0m1.08     \u001b[0m | \u001b[0m24.5     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:15<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m256      \u001b[0m | \u001b[0m-232.6   \u001b[0m | \u001b[0m513.7    \u001b[0m | \u001b[0m778.6    \u001b[0m | \u001b[0m1.662    \u001b[0m | \u001b[0m29.69    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 78%|███████▊  | 194/250 [00:52<00:15,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m257      \u001b[0m | \u001b[0m-267.9   \u001b[0m | \u001b[0m986.3    \u001b[0m | \u001b[0m326.6    \u001b[0m | \u001b[0m3.019    \u001b[0m | \u001b[0m28.35    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:38<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m258      \u001b[0m | \u001b[0m-244.4   \u001b[0m | \u001b[0m523.3    \u001b[0m | \u001b[0m516.0    \u001b[0m | \u001b[0m4.336    \u001b[0m | \u001b[0m4.358    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 61%|██████    | 153/250 [02:01<01:16,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m259      \u001b[0m | \u001b[0m-269.2   \u001b[0m | \u001b[0m1.967e+03\u001b[0m | \u001b[0m379.1    \u001b[0m | \u001b[0m3.398    \u001b[0m | \u001b[0m9.036    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 81%|████████  | 202/250 [00:38<00:09,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m260      \u001b[0m | \u001b[0m-210.3   \u001b[0m | \u001b[0m1.744e+03\u001b[0m | \u001b[0m336.1    \u001b[0m | \u001b[0m1.097    \u001b[0m | \u001b[0m8.535    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:29<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m261      \u001b[0m | \u001b[0m-235.2   \u001b[0m | \u001b[0m461.6    \u001b[0m | \u001b[0m620.7    \u001b[0m | \u001b[0m3.534    \u001b[0m | \u001b[0m15.78    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 90%|████████▉ | 224/250 [00:30<00:03,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m262      \u001b[0m | \u001b[0m-235.3   \u001b[0m | \u001b[0m627.7    \u001b[0m | \u001b[0m129.9    \u001b[0m | \u001b[0m3.687    \u001b[0m | \u001b[0m9.352    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 70%|███████   | 175/250 [00:38<00:16,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m263      \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m1.207e+03\u001b[0m | \u001b[0m353.1    \u001b[0m | \u001b[0m2.353    \u001b[0m | \u001b[0m12.47    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 78%|███████▊  | 196/250 [00:42<00:11,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m264      \u001b[0m | \u001b[0m-220.6   \u001b[0m | \u001b[0m1.745e+03\u001b[0m | \u001b[0m854.8    \u001b[0m | \u001b[0m1.26     \u001b[0m | \u001b[0m7.931    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:23<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m265      \u001b[0m | \u001b[0m-230.1   \u001b[0m | \u001b[0m381.6    \u001b[0m | \u001b[0m700.8    \u001b[0m | \u001b[0m3.983    \u001b[0m | \u001b[0m9.128    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 160/250 [01:13<00:41,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m266      \u001b[0m | \u001b[0m-268.7   \u001b[0m | \u001b[0m1.833e+03\u001b[0m | \u001b[0m699.8    \u001b[0m | \u001b[0m2.776    \u001b[0m | \u001b[0m13.33    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 68%|██████▊   | 169/250 [01:13<00:35,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m267      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.409e+03\u001b[0m | \u001b[0m654.2    \u001b[0m | \u001b[0m3.441    \u001b[0m | \u001b[0m12.03    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 88%|████████▊ | 220/250 [00:53<00:07,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m268      \u001b[0m | \u001b[0m-266.5   \u001b[0m | \u001b[0m703.8    \u001b[0m | \u001b[0m872.2    \u001b[0m | \u001b[0m4.866    \u001b[0m | \u001b[0m12.65    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 63%|██████▎   | 157/250 [01:16<00:45,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m269      \u001b[0m | \u001b[0m-268.9   \u001b[0m | \u001b[0m1.951e+03\u001b[0m | \u001b[0m544.2    \u001b[0m | \u001b[0m2.593    \u001b[0m | \u001b[0m25.6     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 68%|██████▊   | 171/250 [01:34<00:43,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m270      \u001b[0m | \u001b[0m-268.2   \u001b[0m | \u001b[0m1.322e+03\u001b[0m | \u001b[0m452.2    \u001b[0m | \u001b[0m4.37     \u001b[0m | \u001b[0m29.3     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 68%|██████▊   | 170/250 [01:20<00:37,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m271      \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m1.389e+03\u001b[0m | \u001b[0m774.2    \u001b[0m | \u001b[0m3.052    \u001b[0m | \u001b[0m14.49    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 65%|██████▌   | 163/250 [01:58<01:03,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m272      \u001b[0m | \u001b[0m-269.3   \u001b[0m | \u001b[0m1.89e+03 \u001b[0m | \u001b[0m290.1    \u001b[0m | \u001b[0m3.576    \u001b[0m | \u001b[0m24.4     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:25<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m273      \u001b[0m | \u001b[0m-252.7   \u001b[0m | \u001b[0m338.4    \u001b[0m | \u001b[0m350.0    \u001b[0m | \u001b[0m3.267    \u001b[0m | \u001b[0m22.78    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 71%|███████   | 178/250 [00:37<00:15,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m274      \u001b[0m | \u001b[0m-210.5   \u001b[0m | \u001b[0m1.759e+03\u001b[0m | \u001b[0m643.3    \u001b[0m | \u001b[0m1.022    \u001b[0m | \u001b[0m14.29    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 82%|████████▏ | 204/250 [00:39<00:08,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m275      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m814.4    \u001b[0m | \u001b[0m333.1    \u001b[0m | \u001b[0m3.864    \u001b[0m | \u001b[0m10.23    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 74%|███████▎  | 184/250 [00:29<00:10,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m276      \u001b[0m | \u001b[0m-215.0   \u001b[0m | \u001b[0m1.515e+03\u001b[0m | \u001b[0m351.0    \u001b[0m | \u001b[0m1.177    \u001b[0m | \u001b[0m22.13    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 69%|██████▉   | 172/250 [01:22<00:37,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m277      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.303e+03\u001b[0m | \u001b[0m406.7    \u001b[0m | \u001b[0m4.919    \u001b[0m | \u001b[0m9.704    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 86%|████████▌ | 214/250 [00:41<00:06,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m278      \u001b[0m | \u001b[0m-268.2   \u001b[0m | \u001b[0m745.5    \u001b[0m | \u001b[0m238.5    \u001b[0m | \u001b[0m3.762    \u001b[0m | \u001b[0m18.6     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 161/250 [01:29<00:49,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m279      \u001b[0m | \u001b[0m-268.0   \u001b[0m | \u001b[0m1.708e+03\u001b[0m | \u001b[0m390.2    \u001b[0m | \u001b[0m3.923    \u001b[0m | \u001b[0m11.9     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 67%|██████▋   | 167/250 [02:26<01:13,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m280      \u001b[0m | \u001b[0m-268.7   \u001b[0m | \u001b[0m1.741e+03\u001b[0m | \u001b[0m897.7    \u001b[0m | \u001b[0m4.252    \u001b[0m | \u001b[0m25.48    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:10<00:00, 24.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m281      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m216.6    \u001b[0m | \u001b[0m390.8    \u001b[0m | \u001b[0m1.451    \u001b[0m | \u001b[0m29.32    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 68%|██████▊   | 170/250 [00:44<00:20,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m282      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.3e+03  \u001b[0m | \u001b[0m579.9    \u001b[0m | \u001b[0m2.734    \u001b[0m | \u001b[0m14.84    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 66%|██████▌   | 165/250 [02:02<01:02,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m283      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.656e+03\u001b[0m | \u001b[0m516.7    \u001b[0m | \u001b[0m4.953    \u001b[0m | \u001b[0m10.75    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:26<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m284      \u001b[0m | \u001b[0m-296.0   \u001b[0m | \u001b[0m145.8    \u001b[0m | \u001b[0m354.7    \u001b[0m | \u001b[0m4.452    \u001b[0m | \u001b[0m23.78    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 73%|███████▎  | 183/250 [00:47<00:17,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m285      \u001b[0m | \u001b[0m-210.8   \u001b[0m | \u001b[0m1.939e+03\u001b[0m | \u001b[0m769.4    \u001b[0m | \u001b[0m1.739    \u001b[0m | \u001b[0m23.88    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 71%|███████   | 178/250 [01:27<00:35,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m286      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.38e+03 \u001b[0m | \u001b[0m134.3    \u001b[0m | \u001b[0m4.23     \u001b[0m | \u001b[0m1.73     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:07<00:00, 34.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m287      \u001b[0m | \u001b[0m-252.8   \u001b[0m | \u001b[0m220.5    \u001b[0m | \u001b[0m366.0    \u001b[0m | \u001b[0m1.69     \u001b[0m | \u001b[0m10.33    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 72%|███████▏  | 180/250 [00:35<00:13,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m288      \u001b[0m | \u001b[0m-267.6   \u001b[0m | \u001b[0m1.122e+03\u001b[0m | \u001b[0m576.3    \u001b[0m | \u001b[0m2.737    \u001b[0m | \u001b[0m1.964    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 91%|█████████ | 228/250 [00:23<00:02,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m289      \u001b[0m | \u001b[0m-232.0   \u001b[0m | \u001b[0m688.2    \u001b[0m | \u001b[0m413.3    \u001b[0m | \u001b[0m2.074    \u001b[0m | \u001b[0m4.728    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 66%|██████▌   | 165/250 [01:24<00:43,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m290      \u001b[0m | \u001b[0m-268.7   \u001b[0m | \u001b[0m1.509e+03\u001b[0m | \u001b[0m247.9    \u001b[0m | \u001b[0m3.87     \u001b[0m | \u001b[0m27.06    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 76%|███████▌  | 189/250 [01:41<00:32,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m291      \u001b[0m | \u001b[0m-266.9   \u001b[0m | \u001b[0m1.138e+03\u001b[0m | \u001b[0m906.9    \u001b[0m | \u001b[0m4.671    \u001b[0m | \u001b[0m23.02    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:14<00:00, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m292      \u001b[0m | \u001b[0m-241.4   \u001b[0m | \u001b[0m448.5    \u001b[0m | \u001b[0m883.1    \u001b[0m | \u001b[0m1.617    \u001b[0m | \u001b[0m27.1     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m293      \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.719e+03\u001b[0m | \u001b[0m581.0    \u001b[0m | \u001b[0m3.324    \u001b[0m | \u001b[0m21.74    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 75%|███████▌  | 188/250 [00:25<00:08,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m294      \u001b[0m | \u001b[0m-212.4   \u001b[0m | \u001b[0m1.225e+03\u001b[0m | \u001b[0m678.3    \u001b[0m | \u001b[0m1.043    \u001b[0m | \u001b[0m13.79    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 72%|███████▏  | 180/250 [00:40<00:15,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m295      \u001b[0m | \u001b[0m-213.8   \u001b[0m | \u001b[0m1.822e+03\u001b[0m | \u001b[0m415.4    \u001b[0m | \u001b[0m1.123    \u001b[0m | \u001b[0m26.02    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 66%|██████▌   | 165/250 [01:24<00:43,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m296      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.567e+03\u001b[0m | \u001b[0m720.9    \u001b[0m | \u001b[0m3.387    \u001b[0m | \u001b[0m10.82    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 85%|████████▌ | 213/250 [00:34<00:06,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m297      \u001b[0m | \u001b[0m-209.3   \u001b[0m | \u001b[0m1.443e+03\u001b[0m | \u001b[0m840.4    \u001b[0m | \u001b[0m1.477    \u001b[0m | \u001b[0m15.52    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:11<00:00, 22.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m298      \u001b[0m | \u001b[0m-247.9   \u001b[0m | \u001b[0m329.6    \u001b[0m | \u001b[0m938.3    \u001b[0m | \u001b[0m1.072    \u001b[0m | \u001b[0m23.23    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 81%|████████  | 202/250 [00:22<00:05,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m299      \u001b[0m | \u001b[0m-216.4   \u001b[0m | \u001b[0m1.197e+03\u001b[0m | \u001b[0m136.4    \u001b[0m | \u001b[0m1.366    \u001b[0m | \u001b[0m15.93    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 73%|███████▎  | 183/250 [00:35<00:13,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m300      \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m916.1    \u001b[0m | \u001b[0m996.7    \u001b[0m | \u001b[0m2.368    \u001b[0m | \u001b[0m17.47    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:08<00:00, 29.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m301      \u001b[0m | \u001b[0m-245.3   \u001b[0m | \u001b[0m220.9    \u001b[0m | \u001b[0m117.6    \u001b[0m | \u001b[0m2.277    \u001b[0m | \u001b[0m2.605    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 160/250 [01:20<00:45,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m302      \u001b[0m | \u001b[0m-268.7   \u001b[0m | \u001b[0m1.771e+03\u001b[0m | \u001b[0m718.0    \u001b[0m | \u001b[0m2.187    \u001b[0m | \u001b[0m11.24    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 161/250 [02:12<01:13,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m303      \u001b[0m | \u001b[0m-268.7   \u001b[0m | \u001b[0m1.781e+03\u001b[0m | \u001b[0m338.3    \u001b[0m | \u001b[0m4.195    \u001b[0m | \u001b[0m23.17    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 81%|████████  | 203/250 [00:29<00:06,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m304      \u001b[0m | \u001b[0m-210.7   \u001b[0m | \u001b[0m1.258e+03\u001b[0m | \u001b[0m887.8    \u001b[0m | \u001b[0m1.868    \u001b[0m | \u001b[0m24.79    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 83%|████████▎ | 207/250 [00:29<00:06,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m305      \u001b[0m | \u001b[0m-214.9   \u001b[0m | \u001b[0m1.525e+03\u001b[0m | \u001b[0m114.4    \u001b[0m | \u001b[0m1.524    \u001b[0m | \u001b[0m2.986    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:11<00:00, 22.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m306      \u001b[0m | \u001b[0m-235.9   \u001b[0m | \u001b[0m456.0    \u001b[0m | \u001b[0m937.4    \u001b[0m | \u001b[0m1.037    \u001b[0m | \u001b[0m10.44    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 74%|███████▍  | 185/250 [00:44<00:15,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m307      \u001b[0m | \u001b[0m-268.2   \u001b[0m | \u001b[0m1.231e+03\u001b[0m | \u001b[0m234.0    \u001b[0m | \u001b[0m2.122    \u001b[0m | \u001b[0m27.46    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 97%|█████████▋| 242/250 [00:12<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m308      \u001b[0m | \u001b[0m-232.7   \u001b[0m | \u001b[0m560.8    \u001b[0m | \u001b[0m573.3    \u001b[0m | \u001b[0m1.591    \u001b[0m | \u001b[0m13.77    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 63%|██████▎   | 158/250 [01:49<01:03,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m309      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.734e+03\u001b[0m | \u001b[0m587.1    \u001b[0m | \u001b[0m3.504    \u001b[0m | \u001b[0m29.02    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 73%|███████▎  | 183/250 [00:42<00:15,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m310      \u001b[0m | \u001b[0m-268.0   \u001b[0m | \u001b[0m1.129e+03\u001b[0m | \u001b[0m911.3    \u001b[0m | \u001b[0m2.911    \u001b[0m | \u001b[0m12.31    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 94%|█████████▎| 234/250 [00:24<00:01,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m311      \u001b[0m | \u001b[0m-231.5   \u001b[0m | \u001b[0m679.5    \u001b[0m | \u001b[0m630.8    \u001b[0m | \u001b[0m2.57     \u001b[0m | \u001b[0m3.328    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 63%|██████▎   | 157/250 [02:49<01:40,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m312      \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m1.862e+03\u001b[0m | \u001b[0m811.1    \u001b[0m | \u001b[0m4.436    \u001b[0m | \u001b[0m11.96    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 73%|███████▎  | 182/250 [00:31<00:11,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m313      \u001b[0m | \u001b[0m-224.1   \u001b[0m | \u001b[0m1.618e+03\u001b[0m | \u001b[0m367.2    \u001b[0m | \u001b[0m1.515    \u001b[0m | \u001b[0m3.895    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 91%|█████████ | 227/250 [00:14<00:01, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m314      \u001b[0m | \u001b[0m-232.8   \u001b[0m | \u001b[0m722.0    \u001b[0m | \u001b[0m627.8    \u001b[0m | \u001b[0m1.509    \u001b[0m | \u001b[0m6.169    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 93%|█████████▎| 232/250 [00:47<00:03,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m315      \u001b[0m | \u001b[0m-267.4   \u001b[0m | \u001b[0m615.9    \u001b[0m | \u001b[0m844.9    \u001b[0m | \u001b[0m4.959    \u001b[0m | \u001b[0m12.18    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 74%|███████▎  | 184/250 [00:42<00:15,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m316      \u001b[0m | \u001b[0m-212.2   \u001b[0m | \u001b[0m1.899e+03\u001b[0m | \u001b[0m163.4    \u001b[0m | \u001b[0m1.974    \u001b[0m | \u001b[0m24.52    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 160/250 [01:39<00:55,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m317      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.783e+03\u001b[0m | \u001b[0m502.3    \u001b[0m | \u001b[0m3.597    \u001b[0m | \u001b[0m28.24    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 96%|█████████▋| 241/250 [01:22<00:03,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m318      \u001b[0m | \u001b[0m-226.7   \u001b[0m | \u001b[0m1.518e+03\u001b[0m | \u001b[0m299.3    \u001b[0m | \u001b[0m2.846    \u001b[0m | \u001b[0m13.11    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:15<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m319      \u001b[0m | \u001b[0m-304.3   \u001b[0m | \u001b[0m175.8    \u001b[0m | \u001b[0m761.5    \u001b[0m | \u001b[0m4.878    \u001b[0m | \u001b[0m3.577    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 68%|██████▊   | 169/250 [01:47<00:51,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m320      \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.567e+03\u001b[0m | \u001b[0m506.3    \u001b[0m | \u001b[0m4.693    \u001b[0m | \u001b[0m4.076    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 78%|███████▊  | 194/250 [00:52<00:15,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m321      \u001b[0m | \u001b[0m-266.8   \u001b[0m | \u001b[0m937.8    \u001b[0m | \u001b[0m829.9    \u001b[0m | \u001b[0m3.389    \u001b[0m | \u001b[0m7.49     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:06<00:00, 37.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m322      \u001b[0m | \u001b[0m-256.2   \u001b[0m | \u001b[0m265.4    \u001b[0m | \u001b[0m164.7    \u001b[0m | \u001b[0m1.479    \u001b[0m | \u001b[0m6.091    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 161/250 [01:04<00:35,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m323      \u001b[0m | \u001b[0m-268.8   \u001b[0m | \u001b[0m1.764e+03\u001b[0m | \u001b[0m570.4    \u001b[0m | \u001b[0m2.894    \u001b[0m | \u001b[0m4.783    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:17<00:00, 14.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m324      \u001b[0m | \u001b[0m-219.3   \u001b[0m | \u001b[0m665.1    \u001b[0m | \u001b[0m475.4    \u001b[0m | \u001b[0m1.335    \u001b[0m | \u001b[0m28.21    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 95%|█████████▍| 237/250 [00:21<00:01, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m325      \u001b[0m | \u001b[0m-229.4   \u001b[0m | \u001b[0m619.0    \u001b[0m | \u001b[0m283.9    \u001b[0m | \u001b[0m2.558    \u001b[0m | \u001b[0m11.78    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 88%|████████▊ | 219/250 [00:51<00:07,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m326      \u001b[0m | \u001b[0m-267.1   \u001b[0m | \u001b[0m668.0    \u001b[0m | \u001b[0m473.8    \u001b[0m | \u001b[0m4.074    \u001b[0m | \u001b[0m27.96    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 92%|█████████▏| 230/250 [00:14<00:01, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m327      \u001b[0m | \u001b[0m-228.0   \u001b[0m | \u001b[0m722.3    \u001b[0m | \u001b[0m628.7    \u001b[0m | \u001b[0m1.931    \u001b[0m | \u001b[0m8.351    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 97%|█████████▋| 243/250 [01:21<00:02,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m328      \u001b[0m | \u001b[0m-226.8   \u001b[0m | \u001b[0m1.519e+03\u001b[0m | \u001b[0m298.3    \u001b[0m | \u001b[0m2.794    \u001b[0m | \u001b[0m14.09    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 88%|████████▊ | 221/250 [00:23<00:03,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m329      \u001b[0m | \u001b[0m-233.4   \u001b[0m | \u001b[0m1.003e+03\u001b[0m | \u001b[0m970.5    \u001b[0m | \u001b[0m1.51     \u001b[0m | \u001b[0m3.042    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 70%|██████▉   | 174/250 [01:09<00:30,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m330      \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.384e+03\u001b[0m | \u001b[0m108.1    \u001b[0m | \u001b[0m3.901    \u001b[0m | \u001b[0m11.84    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 66%|██████▋   | 166/250 [01:07<00:33,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m331      \u001b[0m | \u001b[0m-269.0   \u001b[0m | \u001b[0m1.526e+03\u001b[0m | \u001b[0m114.6    \u001b[0m | \u001b[0m3.597    \u001b[0m | \u001b[0m2.4      \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 86%|████████▌ | 214/250 [00:30<00:05,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m332      \u001b[0m | \u001b[0m-213.3   \u001b[0m | \u001b[0m1.229e+03\u001b[0m | \u001b[0m678.5    \u001b[0m | \u001b[0m1.254    \u001b[0m | \u001b[0m11.15    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 161/250 [02:24<01:19,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m333      \u001b[0m | \u001b[0m-269.5   \u001b[0m | \u001b[0m1.87e+03 \u001b[0m | \u001b[0m623.5    \u001b[0m | \u001b[0m4.499    \u001b[0m | \u001b[0m19.13    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:40<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m334      \u001b[0m | \u001b[0m-227.4   \u001b[0m | \u001b[0m569.2    \u001b[0m | \u001b[0m574.4    \u001b[0m | \u001b[0m3.727    \u001b[0m | \u001b[0m21.18    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 93%|█████████▎| 232/250 [00:39<00:03,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m335      \u001b[0m | \u001b[0m-265.7   \u001b[0m | \u001b[0m621.1    \u001b[0m | \u001b[0m283.4    \u001b[0m | \u001b[0m4.067    \u001b[0m | \u001b[0m10.54    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 83%|████████▎ | 208/250 [00:33<00:06,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m336      \u001b[0m | \u001b[0m-214.7   \u001b[0m | \u001b[0m1.425e+03\u001b[0m | \u001b[0m357.7    \u001b[0m | \u001b[0m1.622    \u001b[0m | \u001b[0m17.22    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 80%|███████▉  | 199/250 [00:25<00:06,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m337      \u001b[0m | \u001b[0m-209.8   \u001b[0m | \u001b[0m1.229e+03\u001b[0m | \u001b[0m680.7    \u001b[0m | \u001b[0m1.541    \u001b[0m | \u001b[0m10.59    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:36<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m338      \u001b[0m | \u001b[0m-216.4   \u001b[0m | \u001b[0m745.3    \u001b[0m | \u001b[0m796.8    \u001b[0m | \u001b[0m2.902    \u001b[0m | \u001b[0m26.33    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 66%|██████▌   | 165/250 [01:38<00:50,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m339      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.681e+03\u001b[0m | \u001b[0m864.0    \u001b[0m | \u001b[0m3.151    \u001b[0m | \u001b[0m19.1     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 65%|██████▌   | 163/250 [01:13<00:39,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m340      \u001b[0m | \u001b[0m-268.7   \u001b[0m | \u001b[0m1.684e+03\u001b[0m | \u001b[0m862.3    \u001b[0m | \u001b[0m2.077    \u001b[0m | \u001b[0m10.46    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 79%|███████▉  | 197/250 [00:25<00:06,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m341      \u001b[0m | \u001b[0m-218.9   \u001b[0m | \u001b[0m1.227e+03\u001b[0m | \u001b[0m679.7    \u001b[0m | \u001b[0m1.329    \u001b[0m | \u001b[0m12.01    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 70%|███████   | 176/250 [01:25<00:36,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m342      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.447e+03\u001b[0m | \u001b[0m856.3    \u001b[0m | \u001b[0m3.026    \u001b[0m | \u001b[0m22.69    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 83%|████████▎ | 207/250 [00:29<00:06,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m343      \u001b[0m | \u001b[0m-254.8   \u001b[0m | \u001b[0m695.9    \u001b[0m | \u001b[0m144.4    \u001b[0m | \u001b[0m3.432    \u001b[0m | \u001b[0m2.947    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 77%|███████▋  | 193/250 [00:29<00:08,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m344      \u001b[0m | \u001b[0m-255.7   \u001b[0m | \u001b[0m901.0    \u001b[0m | \u001b[0m320.8    \u001b[0m | \u001b[0m2.683    \u001b[0m | \u001b[0m11.23    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 160/250 [01:04<00:36,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m345      \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.678e+03\u001b[0m | \u001b[0m860.2    \u001b[0m | \u001b[0m2.623    \u001b[0m | \u001b[0m9.261    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 85%|████████▍ | 212/250 [00:35<00:06,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m346      \u001b[0m | \u001b[0m-267.0   \u001b[0m | \u001b[0m720.3    \u001b[0m | \u001b[0m625.6    \u001b[0m | \u001b[0m3.176    \u001b[0m | \u001b[0m6.711    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m347      \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.679e+03\u001b[0m | \u001b[0m858.7    \u001b[0m | \u001b[0m3.268    \u001b[0m | \u001b[0m13.06    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 80%|███████▉  | 199/250 [00:25<00:06,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m348      \u001b[0m | \u001b[0m-209.8   \u001b[0m | \u001b[0m1.23e+03 \u001b[0m | \u001b[0m680.6    \u001b[0m | \u001b[0m1.943    \u001b[0m | \u001b[0m10.73    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 70%|███████   | 175/250 [00:36<00:15,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m349      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.199e+03\u001b[0m | \u001b[0m138.0    \u001b[0m | \u001b[0m2.617    \u001b[0m | \u001b[0m13.36    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 80%|███████▉  | 199/250 [00:41<00:10,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m350      \u001b[0m | \u001b[95m-203.9   \u001b[0m | \u001b[95m1.684e+03\u001b[0m | \u001b[95m861.1    \u001b[0m | \u001b[95m1.607    \u001b[0m | \u001b[95m17.37    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 72%|███████▏  | 181/250 [00:58<00:22,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m351      \u001b[0m | \u001b[0m-261.5   \u001b[0m | \u001b[0m1.461e+03\u001b[0m | \u001b[0m745.0    \u001b[0m | \u001b[0m2.645    \u001b[0m | \u001b[0m18.59    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 78%|███████▊  | 194/250 [00:32<00:09,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m352      \u001b[0m | \u001b[0m-267.1   \u001b[0m | \u001b[0m904.3    \u001b[0m | \u001b[0m322.2    \u001b[0m | \u001b[0m2.269    \u001b[0m | \u001b[0m7.671    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 83%|████████▎ | 208/250 [00:23<00:04,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m353      \u001b[0m | \u001b[0m-217.4   \u001b[0m | \u001b[0m1.094e+03\u001b[0m | \u001b[0m199.9    \u001b[0m | \u001b[0m1.135    \u001b[0m | \u001b[0m25.93    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 75%|███████▌  | 188/250 [00:29<00:09,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m354      \u001b[0m | \u001b[0m-222.7   \u001b[0m | \u001b[0m1.29e+03 \u001b[0m | \u001b[0m943.5    \u001b[0m | \u001b[0m1.286    \u001b[0m | \u001b[0m24.06    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▍   | 160/250 [00:57<00:32,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m355      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.743e+03\u001b[0m | \u001b[0m333.6    \u001b[0m | \u001b[0m2.224    \u001b[0m | \u001b[0m7.63     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 71%|███████   | 177/250 [00:44<00:18,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m356      \u001b[0m | \u001b[0m-267.4   \u001b[0m | \u001b[0m1.23e+03 \u001b[0m | \u001b[0m679.5    \u001b[0m | \u001b[0m2.149    \u001b[0m | \u001b[0m12.36    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 76%|███████▌  | 190/250 [01:02<00:19,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m357      \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.069e+03\u001b[0m | \u001b[0m781.7    \u001b[0m | \u001b[0m3.269    \u001b[0m | \u001b[0m21.9     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 75%|███████▍  | 187/250 [00:35<00:12,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m358      \u001b[0m | \u001b[0m-211.2   \u001b[0m | \u001b[0m1.564e+03\u001b[0m | \u001b[0m615.5    \u001b[0m | \u001b[0m1.218    \u001b[0m | \u001b[0m22.91    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:20<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m359      \u001b[0m | \u001b[0m-237.2   \u001b[0m | \u001b[0m457.1    \u001b[0m | \u001b[0m935.3    \u001b[0m | \u001b[0m2.739    \u001b[0m | \u001b[0m9.63     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 89%|████████▉ | 222/250 [00:14<00:01, 15.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m360      \u001b[0m | \u001b[0m-239.4   \u001b[0m | \u001b[0m720.4    \u001b[0m | \u001b[0m630.0    \u001b[0m | \u001b[0m1.22     \u001b[0m | \u001b[0m7.808    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 99%|█████████▉| 248/250 [00:14<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m361      \u001b[0m | \u001b[0m-231.9   \u001b[0m | \u001b[0m567.8    \u001b[0m | \u001b[0m573.2    \u001b[0m | \u001b[0m1.796    \u001b[0m | \u001b[0m22.2     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 85%|████████▌ | 213/250 [00:50<00:08,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m362      \u001b[0m | \u001b[0m-266.7   \u001b[0m | \u001b[0m777.1    \u001b[0m | \u001b[0m937.0    \u001b[0m | \u001b[0m3.013    \u001b[0m | \u001b[0m27.71    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 75%|███████▌  | 188/250 [00:37<00:12,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m363      \u001b[0m | \u001b[0m-266.5   \u001b[0m | \u001b[0m1.092e+03\u001b[0m | \u001b[0m199.8    \u001b[0m | \u001b[0m2.082    \u001b[0m | \u001b[0m24.88    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 68%|██████▊   | 170/250 [01:06<00:31,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m364      \u001b[0m | \u001b[0m-263.5   \u001b[0m | \u001b[0m1.788e+03\u001b[0m | \u001b[0m114.4    \u001b[0m | \u001b[0m2.985    \u001b[0m | \u001b[0m26.07    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 80%|████████  | 200/250 [00:58<00:14,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m365      \u001b[0m | \u001b[0m-267.2   \u001b[0m | \u001b[0m890.0    \u001b[0m | \u001b[0m989.1    \u001b[0m | \u001b[0m3.418    \u001b[0m | \u001b[0m28.87    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 83%|████████▎ | 208/250 [00:25<00:05,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m366      \u001b[0m | \u001b[0m-213.7   \u001b[0m | \u001b[0m1.086e+03\u001b[0m | \u001b[0m651.2    \u001b[0m | \u001b[0m1.082    \u001b[0m | \u001b[0m23.05    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 67%|██████▋   | 167/250 [01:07<00:33,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m367      \u001b[0m | \u001b[0m-268.3   \u001b[0m | \u001b[0m1.559e+03\u001b[0m | \u001b[0m612.7    \u001b[0m | \u001b[0m2.227    \u001b[0m | \u001b[0m21.79    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 83%|████████▎ | 207/250 [00:31<00:06,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m368      \u001b[0m | \u001b[0m-212.5   \u001b[0m | \u001b[0m1.292e+03\u001b[0m | \u001b[0m946.0    \u001b[0m | \u001b[0m1.829    \u001b[0m | \u001b[0m23.23    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 70%|███████   | 175/250 [00:50<00:21,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m369      \u001b[0m | \u001b[0m-268.2   \u001b[0m | \u001b[0m1.291e+03\u001b[0m | \u001b[0m944.5    \u001b[0m | \u001b[0m2.258    \u001b[0m | \u001b[0m23.02    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:42<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m370      \u001b[0m | \u001b[0m-251.6   \u001b[0m | \u001b[0m656.5    \u001b[0m | \u001b[0m665.3    \u001b[0m | \u001b[0m3.409    \u001b[0m | \u001b[0m13.16    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 87%|████████▋ | 218/250 [00:31<00:04,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m371      \u001b[0m | \u001b[0m-230.8   \u001b[0m | \u001b[0m744.3    \u001b[0m | \u001b[0m796.8    \u001b[0m | \u001b[0m2.714    \u001b[0m | \u001b[0m23.65    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 87%|████████▋ | 217/250 [00:23<00:03,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m372      \u001b[0m | \u001b[0m-219.8   \u001b[0m | \u001b[0m891.7    \u001b[0m | \u001b[0m991.4    \u001b[0m | \u001b[0m1.222    \u001b[0m | \u001b[0m27.83    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 86%|████████▋ | 216/250 [00:29<00:04,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m373      \u001b[0m | \u001b[95m-201.7   \u001b[0m | \u001b[95m1.229e+03\u001b[0m | \u001b[95m680.6    \u001b[0m | \u001b[95m1.449    \u001b[0m | \u001b[95m11.4     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 96%|█████████▋| 241/250 [00:30<00:01,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m374      \u001b[0m | \u001b[0m-266.1   \u001b[0m | \u001b[0m600.7    \u001b[0m | \u001b[0m345.5    \u001b[0m | \u001b[0m3.159    \u001b[0m | \u001b[0m5.536    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 84%|████████▍ | 211/250 [00:13<00:02, 15.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m375      \u001b[0m | \u001b[0m-240.6   \u001b[0m | \u001b[0m721.1    \u001b[0m | \u001b[0m629.6    \u001b[0m | \u001b[0m1.608    \u001b[0m | \u001b[0m10.2     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 98%|█████████▊| 246/250 [00:11<00:00, 20.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m376      \u001b[0m | \u001b[0m-230.9   \u001b[0m | \u001b[0m581.3    \u001b[0m | \u001b[0m300.6    \u001b[0m | \u001b[0m1.305    \u001b[0m | \u001b[0m7.246    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 73%|███████▎  | 183/250 [00:37<00:13,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m377      \u001b[0m | \u001b[0m-214.0   \u001b[0m | \u001b[0m1.677e+03\u001b[0m | \u001b[0m863.2    \u001b[0m | \u001b[0m1.615    \u001b[0m | \u001b[0m13.3     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 68%|██████▊   | 170/250 [01:29<00:42,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m378      \u001b[0m | \u001b[0m-268.5   \u001b[0m | \u001b[0m1.422e+03\u001b[0m | \u001b[0m358.4    \u001b[0m | \u001b[0m4.183    \u001b[0m | \u001b[0m16.03    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 72%|███████▏  | 180/250 [01:00<00:23,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m379      \u001b[0m | \u001b[0m-268.1   \u001b[0m | \u001b[0m1.169e+03\u001b[0m | \u001b[0m210.4    \u001b[0m | \u001b[0m3.543    \u001b[0m | \u001b[0m26.35    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 62%|██████▏   | 154/250 [01:16<00:47,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m380      \u001b[0m | \u001b[0m-268.9   \u001b[0m | \u001b[0m1.938e+03\u001b[0m | \u001b[0m769.4    \u001b[0m | \u001b[0m2.913    \u001b[0m | \u001b[0m22.26    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 70%|███████   | 176/250 [00:36<00:15,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m381      \u001b[0m | \u001b[0m-215.8   \u001b[0m | \u001b[0m1.686e+03\u001b[0m | \u001b[0m860.4    \u001b[0m | \u001b[0m1.093    \u001b[0m | \u001b[0m17.42    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 75%|███████▍  | 187/250 [00:43<00:14,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m382      \u001b[0m | \u001b[0m-213.3   \u001b[0m | \u001b[0m1.677e+03\u001b[0m | \u001b[0m861.5    \u001b[0m | \u001b[0m1.71     \u001b[0m | \u001b[0m15.84    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 72%|███████▏  | 181/250 [00:41<00:15,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m383      \u001b[0m | \u001b[0m-219.3   \u001b[0m | \u001b[0m1.684e+03\u001b[0m | \u001b[0m863.9    \u001b[0m | \u001b[0m1.146    \u001b[0m | \u001b[0m14.26    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 65%|██████▍   | 162/250 [01:12<00:39,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m384      \u001b[0m | \u001b[0m-268.4   \u001b[0m | \u001b[0m1.686e+03\u001b[0m | \u001b[0m864.1    \u001b[0m | \u001b[0m2.123    \u001b[0m | \u001b[0m16.56    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 68%|██████▊   | 170/250 [01:08<00:32,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m385      \u001b[0m | \u001b[0m-267.9   \u001b[0m | \u001b[0m1.382e+03\u001b[0m | \u001b[0m103.8    \u001b[0m | \u001b[0m3.107    \u001b[0m | \u001b[0m11.75    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:36<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m386      \u001b[0m | \u001b[0m-251.2   \u001b[0m | \u001b[0m356.8    \u001b[0m | \u001b[0m607.2    \u001b[0m | \u001b[0m4.415    \u001b[0m | \u001b[0m24.03    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▎   | 159/250 [01:14<00:42,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m387      \u001b[0m | \u001b[0m-268.7   \u001b[0m | \u001b[0m1.841e+03\u001b[0m | \u001b[0m777.9    \u001b[0m | \u001b[0m2.111    \u001b[0m | \u001b[0m13.73    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 64%|██████▎   | 159/250 [01:56<01:06,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m388      \u001b[0m | \u001b[0m-268.8   \u001b[0m | \u001b[0m1.875e+03\u001b[0m | \u001b[0m623.8    \u001b[0m | \u001b[0m3.089    \u001b[0m | \u001b[0m21.46    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 84%|████████▍ | 210/250 [00:45<00:08,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m389      \u001b[0m | \u001b[0m-268.0   \u001b[0m | \u001b[0m742.1    \u001b[0m | \u001b[0m798.6    \u001b[0m | \u001b[0m3.425    \u001b[0m | \u001b[0m26.38    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 82%|████████▏ | 206/250 [00:28<00:06,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m390      \u001b[0m | \u001b[0m-220.4   \u001b[0m | \u001b[0m1.229e+03\u001b[0m | \u001b[0m677.5    \u001b[0m | \u001b[0m1.226    \u001b[0m | \u001b[0m11.93    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 65%|██████▌   | 163/250 [00:57<00:30,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m391      \u001b[0m | \u001b[0m-268.6   \u001b[0m | \u001b[0m1.564e+03\u001b[0m | \u001b[0m617.0    \u001b[0m | \u001b[0m2.128    \u001b[0m | \u001b[0m20.63    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 65%|██████▌   | 163/250 [02:03<01:05,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m392      \u001b[0m | \u001b[0m-268.9   \u001b[0m | \u001b[0m1.938e+03\u001b[0m | \u001b[0m770.8    \u001b[0m | \u001b[0m3.133    \u001b[0m | \u001b[0m25.05    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 90%|█████████ | 225/250 [00:47<00:05,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m393      \u001b[0m | \u001b[0m-267.7   \u001b[0m | \u001b[0m669.5    \u001b[0m | \u001b[0m673.9    \u001b[0m | \u001b[0m4.767    \u001b[0m | \u001b[0m11.28    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 93%|█████████▎| 233/250 [00:24<00:01,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m394      \u001b[0m | \u001b[0m-235.3   \u001b[0m | \u001b[0m602.7    \u001b[0m | \u001b[0m215.4    \u001b[0m | \u001b[0m2.403    \u001b[0m | \u001b[0m26.29    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 97%|█████████▋| 242/250 [00:48<00:01,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m395      \u001b[0m | \u001b[0m-258.0   \u001b[0m | \u001b[0m567.6    \u001b[0m | \u001b[0m574.7    \u001b[0m | \u001b[0m4.965    \u001b[0m | \u001b[0m23.46    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 70%|███████   | 176/250 [00:45<00:19,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m396      \u001b[0m | \u001b[0m-215.8   \u001b[0m | \u001b[0m1.939e+03\u001b[0m | \u001b[0m769.4    \u001b[0m | \u001b[0m1.035    \u001b[0m | \u001b[0m21.8     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 83%|████████▎ | 208/250 [00:33<00:06,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m397      \u001b[0m | \u001b[0m-205.6   \u001b[0m | \u001b[0m1.427e+03\u001b[0m | \u001b[0m355.7    \u001b[0m | \u001b[0m1.899    \u001b[0m | \u001b[0m16.2     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 88%|████████▊ | 221/250 [00:21<00:02, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m398      \u001b[0m | \u001b[0m-221.2   \u001b[0m | \u001b[0m891.2    \u001b[0m | \u001b[0m991.1    \u001b[0m | \u001b[0m1.17     \u001b[0m | \u001b[0m26.72    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|██████████| 250/250 [00:12<00:00, 20.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m399      \u001b[0m | \u001b[0m-222.9   \u001b[0m | \u001b[0m601.1    \u001b[0m | \u001b[0m344.9    \u001b[0m | \u001b[0m1.259    \u001b[0m | \u001b[0m7.498    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      " 82%|████████▏ | 204/250 [00:28<00:06,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m400      \u001b[0m | \u001b[0m-206.1   \u001b[0m | \u001b[0m1.229e+03\u001b[0m | \u001b[0m675.4    \u001b[0m | \u001b[0m1.824    \u001b[0m | \u001b[0m11.88    \u001b[0m |\n",
      "=========================================================================\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/trained_models/AUG23-stim-LS-param_counts.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _run:\n\u001b[1;32m     61\u001b[0m     run_bayes_opt(pbounds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md_model\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2000\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_heads\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m30\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m)}, init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/trained_models/AUG23-stim-LS-param_counts.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLS_param_counts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/numpy/lib/npyio.py:542\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    541\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/trained_models/AUG23-stim-LS-param_counts.npy'"
     ]
    }
   ],
   "source": [
    "_run = True\n",
    "from bayes_opt import BayesianOptimization\n",
    "from models import TransformerOneStep\n",
    "from train import train_transformer, eval_transformer\n",
    "from utils import count_parameters\n",
    "\n",
    "LS_param_counts = []\n",
    "\n",
    "import gc\n",
    "def black_box_function(d_model, num_heads, hidden_dim, n_layers, seed=seed):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    seed = 123\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    hidden_dim, d_model, n_layers, num_heads = int(hidden_dim), int(d_model), int(n_layers), int(num_heads)\n",
    "    d_model = int(int(d_model/num_heads)*num_heads) # d_model must be multiples of n_heads\n",
    "    if d_model %2 != 0:\n",
    "        d_model += num_heads\n",
    "        \n",
    "    DNN = TransformerOneStep(input_dim,\n",
    "                d_model=d_model,\n",
    "                num_heads=num_heads,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                n_encoder_layers=n_layers,\n",
    "                device=device, \n",
    "                max_len=30,\n",
    "                dropout=0.2,\n",
    "                use_mask=False,\n",
    "                pos_output=True,\n",
    "                bin_output=False,\n",
    "                softmax_output=False).to(device)\n",
    "    \n",
    "    optimiser = torch.optim.Adam(DNN.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimiser, gamma=0.99)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, mode='min', factor=0.5, patience=10, threshold=0.01)\n",
    "\n",
    "    return_dict = train_transformer(\n",
    "        model=DNN,\n",
    "        train_loader=train_dataloader_LS, test_loader=valid_dataloader_LS, # use valid loader here\n",
    "        optimiser=optimiser, criterion=criterion, num_epochs=250,\n",
    "        verbose=False, force_stop=False, scheduler=scheduler)\n",
    "\n",
    "    LS_param_counts.append([min(return_dict['eval_losses']), count_parameters(DNN), d_model, num_heads, hidden_dim, n_layers])\n",
    "    valid_loss = -min(return_dict['eval_losses'])   \n",
    "    del DNN, return_dict\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return valid_loss\n",
    "\n",
    "def run_bayes_opt(pbounds, init_points=100, n_iter=100):\n",
    "    optimizer = BayesianOptimization(f=black_box_function, pbounds=pbounds, random_state=123)\n",
    "    optimizer.maximize(init_points=init_points, n_iter=n_iter)\n",
    "\n",
    "if _run:\n",
    "    run_bayes_opt(pbounds = {'d_model':(100, 2000), 'num_heads':(1, 30), 'hidden_dim':(100, 1000), 'n_layers':(1, 5)}, init_points=200, n_iter=200)\n",
    "    np.save(f'./data/trained_models/AUG23-stim-LS-param_counts.npy', np.array(LS_param_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMER\n",
    "# |   iter    |  target   |  d_model  | hidden... | n_layers  | num_heads |\n",
    "# | 147       | -209.5    | 1.463e+03 | 744.2     | 1.164     | 15.97     |\n",
    "# | 1         | -209.1    | 1.423e+03 | 357.5     | 1.907     | 16.99     |\n",
    "\n",
    "d_model = 1423\n",
    "num_heads = 16\n",
    "hidden_dim = 357\n",
    "n_layers = 1\n",
    "\n",
    "d_model = int(int(d_model/num_heads)*num_heads) # d_model must be multiples of n_heads\n",
    "if d_model % 2 != 0:\n",
    "    d_model += num_heads\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from models import TransformerOneStep\n",
    "\n",
    "DNN_LS = TransformerOneStep(input_dim,\n",
    "                d_model=d_model,\n",
    "                num_heads=num_heads,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                n_encoder_layers=n_layers,\n",
    "                device=device, \n",
    "                max_len=30,\n",
    "                dropout=0.2,\n",
    "                decoder='linear',\n",
    "                decoder_hidden_dim=None,\n",
    "                use_mask=True,\n",
    "                pos_output=True,\n",
    "                bin_output=False,\n",
    "                softmax_output=False).to(device)\n",
    "\n",
    "\n",
    "# assert len(np.intersect1d(forward_mse_idx, backward_mse_idx)) == 0\n",
    "# assert len(np.intersect1d(backward_mse_idx, random_mse_idx)) == 0\n",
    "# assert len(np.intersect1d(random_mse_idx, non_stim_mse_idx)) == 0\n",
    "# assert len(np.intersect1d(non_stim_mse_idx, forward_mse_idx)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yc3eukua) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comic-terrain-56</strong> at: <a href='https://wandb.ai/cngzlsh/approx_brain/runs/yc3eukua' target=\"_blank\">https://wandb.ai/cngzlsh/approx_brain/runs/yc3eukua</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240321_124328-yc3eukua/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yc3eukua). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/approx_brain/wandb/run-20240321_125142-q0gok5uz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cngzlsh/approx_brain/runs/q0gok5uz' target=\"_blank\">resilient-thunder-57</a></strong> to <a href='https://wandb.ai/cngzlsh/approx_brain' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cngzlsh/approx_brain' target=\"_blank\">https://wandb.ai/cngzlsh/approx_brain</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cngzlsh/approx_brain/runs/q0gok5uz' target=\"_blank\">https://wandb.ai/cngzlsh/approx_brain/runs/q0gok5uz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial eval loss: 1202.059371805392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/500 [00:00<01:40,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss 1253.2596435546875, eval loss 1149.6242801900864. Time elapsed: 0 h 0 m 0 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 27/500 [00:04<01:26,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: training loss 414.4950866699219, eval loss 352.8755447299783. Time elapsed: 0 h 0 m 4 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 52/500 [00:09<01:22,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: training loss 260.635009765625, eval loss 241.77846835282216. Time elapsed: 0 h 0 m 9 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 77/500 [00:14<01:16,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: training loss 214.94140625, eval loss 230.06022560713137. Time elapsed: 0 h 0 m 13 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 102/500 [00:18<01:12,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: training loss 187.4166717529297, eval loss 232.52389180719405. Time elapsed: 0 h 0 m 18 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 127/500 [00:23<01:07,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126: training loss 180.7676239013672, eval loss 235.93175006462673. Time elapsed: 0 h 0 m 22 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 152/500 [00:27<01:08,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151: training loss 180.48170471191406, eval loss 235.22293450099897. Time elapsed: 0 h 0 m 27 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 177/500 [00:32<01:03,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176: training loss 178.9941864013672, eval loss 234.9568453974581. Time elapsed: 0 h 0 m 32 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 182/500 [00:33<00:59,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial eval loss: 234.96954903825937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<01:38,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss 179.1151885986328, eval loss 248.0306852433664. Time elapsed: 0 h 0 m 0 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 27/500 [00:05<01:34,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: training loss 146.27081298828125, eval loss 254.96389680968323. Time elapsed: 0 h 0 m 5 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 52/500 [00:10<01:27,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: training loss 139.89280700683594, eval loss 256.5646694329051. Time elapsed: 0 h 0 m 10 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 76/500 [00:14<01:22,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: training loss 135.8064727783203, eval loss 255.42498558746396. Time elapsed: 0 h 0 m 14 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [00:19<01:19,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: training loss 137.2113494873047, eval loss 255.5507922106205. Time elapsed: 0 h 0 m 19 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 111/500 [00:22<01:17,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial eval loss: 255.53336705291386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss 137.36705017089844, eval loss 258.02438510822833. Time elapsed: 0 h 0 m 0 s."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<01:38,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 27/500 [00:05<01:39,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: training loss 130.19097900390625, eval loss 263.3375206770003. Time elapsed: 0 h 0 m 5 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 52/500 [00:10<01:28,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: training loss 124.09107971191406, eval loss 263.4111321746494. Time elapsed: 0 h 0 m 10 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 76/500 [00:15<01:23,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: training loss 122.21857452392578, eval loss 263.873854621983. Time elapsed: 0 h 0 m 15 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [00:20<01:19,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: training loss 122.72976684570312, eval loss 263.93478671344826. Time elapsed: 0 h 0 m 20 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 113/500 [00:22<01:17,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial eval loss: 263.80592157516696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<01:35,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss 120.89486694335938, eval loss 262.8032520810395. Time elapsed: 0 h 0 m 0 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 27/500 [00:05<01:33,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: training loss 115.05149841308594, eval loss 259.3262599924344. Time elapsed: 0 h 0 m 5 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 52/500 [00:10<01:28,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: training loss 108.01287078857422, eval loss 259.52381652777075. Time elapsed: 0 h 0 m 10 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 77/500 [00:15<01:23,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: training loss 106.27821350097656, eval loss 261.27925131780233. Time elapsed: 0 h 0 m 15 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 102/500 [00:20<01:18,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: training loss 104.6983871459961, eval loss 261.8296143399282. Time elapsed: 0 h 0 m 19 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 119/500 [00:23<01:15,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial eval loss: 261.85561164933284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<01:37,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss 105.42140197753906, eval loss 266.2646695448162. Time elapsed: 0 h 0 m 0 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 27/500 [00:05<01:33,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: training loss 98.63956451416016, eval loss 261.5809873314111. Time elapsed: 0 h 0 m 5 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 52/500 [00:10<01:28,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: training loss 93.59769439697266, eval loss 263.33031294509124. Time elapsed: 0 h 0 m 10 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 77/500 [00:15<01:23,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: training loss 92.05933380126953, eval loss 265.2449819383746. Time elapsed: 0 h 0 m 15 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 102/500 [00:20<01:18,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: training loss 91.8291015625, eval loss 265.5595931972848. Time elapsed: 0 h 0 m 19 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 106/500 [00:21<01:18,  5.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_transformer, eval_transformer\n\u001b[0;32m---> 19\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_transformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDNN_LS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader_LS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader_LS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstim_type_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# [forward_mse_idx, backward_mse_idx, random_mse_idx, non_stim_mse_idx],\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprev_return_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/approx_brain/train.py:312\u001b[0m, in \u001b[0;36mtrain_transformer\u001b[0;34m(model, train_loader, test_loader, optimiser, criterion, num_epochs, verbose, force_stop, batch_first, scheduler, use_wandb, stim_type_indices, prev_return_dict)\u001b[0m\n\u001b[1;32m    309\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    310\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 312\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_stop:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(project='approx_brain')\n",
    "\n",
    "return_dict = None # intialise as None\n",
    "n_cycles = 15\n",
    "for _ in range(n_cycles):\n",
    "    optimiser = torch.optim.Adam(DNN_LS.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, \n",
    "                                                        mode='min', \n",
    "                                                        factor=0.5, \n",
    "                                                        patience=10, \n",
    "                                                        threshold=0.01)\n",
    "    num_epochs = 500\n",
    "\n",
    "    from train import train_transformer, eval_transformer\n",
    "\n",
    "    return_dict = train_transformer(\n",
    "                model=DNN_LS,\n",
    "                train_loader=train_dataloader_LS,\n",
    "                test_loader=test_dataloader_LS,\n",
    "                optimiser=optimiser,\n",
    "                criterion=criterion,\n",
    "                num_epochs=num_epochs,\n",
    "                verbose=True,\n",
    "                batch_first=True,\n",
    "                scheduler=scheduler,\n",
    "                use_wandb=False,\n",
    "                stim_type_indices= False,\n",
    "                # [forward_mse_idx, backward_mse_idx, random_mse_idx, non_stim_mse_idx],\n",
    "                prev_return_dict=return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Transformer Loss: tensor(247.8197)\n",
      "Transformer prediction for non-stim stim MSE loss:  tensor(246.2046)\n"
     ]
    }
   ],
   "source": [
    "# with open(save_path / f'EB095-stim-LS-transformer-param-metadata-304-19-948-4-trained-30.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "# best_eval_params = torch.load(save_path /f'EB095-stim-LS-transformer-param-304-19-948-4-trained-30.pth')\n",
    "# DNN_LS.load_state_dict(best_eval_params)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y_hat_LS = DNN_LS(X_test.to(device).permute(1,0,2)).permute(1,0,2).cpu()\n",
    "    LS_test_pred_loss = nn.MSELoss(reduction='none')(Y_hat_LS, Y_test[...,LS_neuron_idx])\n",
    "    print('Overall Transformer Loss:', LS_test_pred_loss.sum()/np.prod(LS_test_pred_loss.shape))\n",
    "    # print('Transformer prediction for forward stim MSE loss: ', LS_test_pred_loss[forward_mse_idx].sum()/len(forward_mse_idx)/output_dim)\n",
    "    # print('Transformer prediction for backward stim MSE loss: ', LS_test_pred_loss[backward_mse_idx].sum() / len(backward_mse_idx)/output_dim)\n",
    "    # print('Transformer prediction for random stim MSE loss: ', LS_test_pred_loss[random_mse_idx].sum() / len(random_mse_idx)/output_dim)\n",
    "    print('Transformer prediction for non-stim stim MSE loss: ', LS_test_pred_loss[non_stim_mse_idx].sum() / len(non_stim_mse_idx)/output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 12:35:59.883 | INFO     | __main__:<module>:10 - Loss for LS neuron No 0: 239.88823560996565 (Hz^2).\n",
      "2024-03-21 12:35:59.886 | INFO     | __main__:<module>:12 - Endogenous: 218.68953125\n",
      "2024-03-21 12:36:00.135 | INFO     | __main__:<module>:10 - Loss for LS neuron No 1: 20.612026149054984 (Hz^2).\n",
      "2024-03-21 12:36:00.136 | INFO     | __main__:<module>:12 - Endogenous: 14.587734375\n",
      "2024-03-21 12:36:00.325 | INFO     | __main__:<module>:10 - Loss for LS neuron No 2: 1.8354425069802405 (Hz^2).\n",
      "2024-03-21 12:36:00.326 | INFO     | __main__:<module>:12 - Endogenous: 1.8448068237304687\n",
      "2024-03-21 12:36:00.559 | INFO     | __main__:<module>:10 - Loss for LS neuron No 3: 551.354435137457 (Hz^2).\n",
      "2024-03-21 12:36:00.560 | INFO     | __main__:<module>:12 - Endogenous: 575.7693359375\n",
      "2024-03-21 12:36:00.834 | INFO     | __main__:<module>:10 - Loss for LS neuron No 4: 912.1634450171821 (Hz^2).\n",
      "2024-03-21 12:36:00.835 | INFO     | __main__:<module>:12 - Endogenous: 835.069921875\n",
      "2024-03-21 12:36:01.045 | INFO     | __main__:<module>:10 - Loss for LS neuron No 5: 11.321269766161942 (Hz^2).\n",
      "2024-03-21 12:36:01.046 | INFO     | __main__:<module>:12 - Endogenous: 10.577109375\n",
      "2024-03-21 12:36:01.235 | INFO     | __main__:<module>:10 - Loss for LS neuron No 6: 1.9983566651229596 (Hz^2).\n",
      "2024-03-21 12:36:01.236 | INFO     | __main__:<module>:12 - Endogenous: 2.136253204345703\n",
      "2024-03-21 12:36:01.442 | INFO     | __main__:<module>:10 - Loss for LS neuron No 7: 259.55433848797253 (Hz^2).\n",
      "2024-03-21 12:36:01.443 | INFO     | __main__:<module>:12 - Endogenous: 272.27568359375\n",
      "2024-03-21 12:36:01.668 | INFO     | __main__:<module>:10 - Loss for LS neuron No 8: 760.5113294673539 (Hz^2).\n",
      "2024-03-21 12:36:01.669 | INFO     | __main__:<module>:12 - Endogenous: 778.3865625\n",
      "2024-03-21 12:36:01.921 | INFO     | __main__:<module>:10 - Loss for LS neuron No 9: 373.54585481099656 (Hz^2).\n",
      "2024-03-21 12:36:01.922 | INFO     | __main__:<module>:12 - Endogenous: 382.198203125\n",
      "2024-03-21 12:36:02.175 | INFO     | __main__:<module>:10 - Loss for LS neuron No 10: 404.40619630584195 (Hz^2).\n",
      "2024-03-21 12:36:02.176 | INFO     | __main__:<module>:12 - Endogenous: 395.5365625\n",
      "2024-03-21 12:36:02.406 | INFO     | __main__:<module>:10 - Loss for LS neuron No 11: 416.7214615549828 (Hz^2).\n",
      "2024-03-21 12:36:02.407 | INFO     | __main__:<module>:12 - Endogenous: 431.1538671875\n",
      "2024-03-21 12:36:02.679 | INFO     | __main__:<module>:10 - Loss for LS neuron No 12: 943.5412371134021 (Hz^2).\n",
      "2024-03-21 12:36:02.680 | INFO     | __main__:<module>:12 - Endogenous: 926.954375\n",
      "2024-03-21 12:36:02.909 | INFO     | __main__:<module>:10 - Loss for LS neuron No 13: 81.49365066580756 (Hz^2).\n",
      "2024-03-21 12:36:02.910 | INFO     | __main__:<module>:12 - Endogenous: 79.9000439453125\n",
      "2024-03-21 12:36:03.101 | INFO     | __main__:<module>:10 - Loss for LS neuron No 14: 7.852398115335052 (Hz^2).\n",
      "2024-03-21 12:36:03.102 | INFO     | __main__:<module>:12 - Endogenous: 8.134588623046875\n",
      "2024-03-21 12:36:03.318 | INFO     | __main__:<module>:10 - Loss for LS neuron No 15: 363.1812983247423 (Hz^2).\n",
      "2024-03-21 12:36:03.319 | INFO     | __main__:<module>:12 - Endogenous: 320.57685546875\n",
      "2024-03-21 12:36:03.609 | INFO     | __main__:<module>:10 - Loss for LS neuron No 16: 1333.3022981099657 (Hz^2).\n",
      "2024-03-21 12:36:03.610 | INFO     | __main__:<module>:12 - Endogenous: 1333.976875\n",
      "2024-03-21 12:36:03.818 | INFO     | __main__:<module>:10 - Loss for LS neuron No 17: 366.34654209621993 (Hz^2).\n",
      "2024-03-21 12:36:03.819 | INFO     | __main__:<module>:12 - Endogenous: 397.1867578125\n",
      "2024-03-21 12:36:04.037 | INFO     | __main__:<module>:10 - Loss for LS neuron No 18: 652.1122744845361 (Hz^2).\n",
      "2024-03-21 12:36:04.038 | INFO     | __main__:<module>:12 - Endogenous: 658.37546875\n",
      "2024-03-21 12:36:04.245 | INFO     | __main__:<module>:10 - Loss for LS neuron No 19: 657.7038230240549 (Hz^2).\n",
      "2024-03-21 12:36:04.246 | INFO     | __main__:<module>:12 - Endogenous: 617.074453125\n",
      "2024-03-21 12:36:04.445 | INFO     | __main__:<module>:10 - Loss for LS neuron No 20: 43.798546230670105 (Hz^2).\n",
      "2024-03-21 12:36:04.446 | INFO     | __main__:<module>:12 - Endogenous: 37.9787841796875\n",
      "2024-03-21 12:36:04.667 | INFO     | __main__:<module>:10 - Loss for LS neuron No 21: 696.7683634020618 (Hz^2).\n",
      "2024-03-21 12:36:04.668 | INFO     | __main__:<module>:12 - Endogenous: 668.176875\n",
      "2024-03-21 12:36:04.861 | INFO     | __main__:<module>:10 - Loss for LS neuron No 22: 40.259487086554984 (Hz^2).\n",
      "2024-03-21 12:36:04.862 | INFO     | __main__:<module>:12 - Endogenous: 38.68114990234375\n",
      "2024-03-21 12:36:05.057 | INFO     | __main__:<module>:10 - Loss for LS neuron No 23: 143.54350569158075 (Hz^2).\n",
      "2024-03-21 12:36:05.059 | INFO     | __main__:<module>:12 - Endogenous: 138.037177734375\n",
      "2024-03-21 12:36:05.308 | INFO     | __main__:<module>:10 - Loss for LS neuron No 24: 856.0284579037801 (Hz^2).\n",
      "2024-03-21 12:36:05.309 | INFO     | __main__:<module>:12 - Endogenous: 844.17171875\n",
      "2024-03-21 12:36:05.501 | INFO     | __main__:<module>:10 - Loss for LS neuron No 25: 70.49163713487972 (Hz^2).\n",
      "2024-03-21 12:36:05.502 | INFO     | __main__:<module>:12 - Endogenous: 69.0830029296875\n",
      "2024-03-21 12:36:05.708 | INFO     | __main__:<module>:10 - Loss for LS neuron No 26: 301.0001610824742 (Hz^2).\n",
      "2024-03-21 12:36:05.709 | INFO     | __main__:<module>:12 - Endogenous: 306.83814453125\n",
      "2024-03-21 12:36:05.894 | INFO     | __main__:<module>:10 - Loss for LS neuron No 27: 10.750786955004296 (Hz^2).\n",
      "2024-03-21 12:36:05.895 | INFO     | __main__:<module>:12 - Endogenous: 7.9049072265625\n",
      "2024-03-21 12:36:06.090 | INFO     | __main__:<module>:10 - Loss for LS neuron No 28: 24.698913364475946 (Hz^2).\n",
      "2024-03-21 12:36:06.091 | INFO     | __main__:<module>:12 - Endogenous: 23.55954345703125\n",
      "2024-03-21 12:36:06.279 | INFO     | __main__:<module>:10 - Loss for LS neuron No 29: 7.289255463380584 (Hz^2).\n",
      "2024-03-21 12:36:06.280 | INFO     | __main__:<module>:12 - Endogenous: 6.989471435546875\n",
      "2024-03-21 12:36:06.451 | INFO     | __main__:<module>:10 - Loss for LS neuron No 30: 5.854195191688144 (Hz^2).\n",
      "2024-03-21 12:36:06.452 | INFO     | __main__:<module>:12 - Endogenous: 6.30578857421875\n",
      "2024-03-21 12:36:06.654 | INFO     | __main__:<module>:10 - Loss for LS neuron No 31: 35.20148732817869 (Hz^2).\n",
      "2024-03-21 12:36:06.655 | INFO     | __main__:<module>:12 - Endogenous: 37.41656982421875\n",
      "2024-03-21 12:36:06.859 | INFO     | __main__:<module>:10 - Loss for LS neuron No 32: 54.46472293814433 (Hz^2).\n",
      "2024-03-21 12:36:06.860 | INFO     | __main__:<module>:12 - Endogenous: 48.0258056640625\n",
      "2024-03-21 12:36:07.086 | INFO     | __main__:<module>:10 - Loss for LS neuron No 33: 55.476508805841924 (Hz^2).\n",
      "2024-03-21 12:36:07.087 | INFO     | __main__:<module>:12 - Endogenous: 57.4255322265625\n",
      "2024-03-21 12:36:07.276 | INFO     | __main__:<module>:10 - Loss for LS neuron No 34: 191.04394866838487 (Hz^2).\n",
      "2024-03-21 12:36:07.277 | INFO     | __main__:<module>:12 - Endogenous: 198.5453515625\n",
      "2024-03-21 12:36:07.444 | INFO     | __main__:<module>:10 - Loss for LS neuron No 35: 6.480484690453179 (Hz^2).\n",
      "2024-03-21 12:36:07.446 | INFO     | __main__:<module>:12 - Endogenous: 3.833507080078125\n",
      "2024-03-21 12:36:07.633 | INFO     | __main__:<module>:10 - Loss for LS neuron No 36: 76.27864583333333 (Hz^2).\n",
      "2024-03-21 12:36:07.634 | INFO     | __main__:<module>:12 - Endogenous: 65.8903564453125\n",
      "2024-03-21 12:36:07.827 | INFO     | __main__:<module>:10 - Loss for LS neuron No 37: 165.43795640034364 (Hz^2).\n",
      "2024-03-21 12:36:07.827 | INFO     | __main__:<module>:12 - Endogenous: 140.070126953125\n",
      "2024-03-21 12:36:08.014 | INFO     | __main__:<module>:10 - Loss for LS neuron No 38: 36.70230616408935 (Hz^2).\n",
      "2024-03-21 12:36:08.015 | INFO     | __main__:<module>:12 - Endogenous: 36.53550048828125\n",
      "2024-03-21 12:36:08.198 | INFO     | __main__:<module>:10 - Loss for LS neuron No 39: 66.8654827104811 (Hz^2).\n",
      "2024-03-21 12:36:08.199 | INFO     | __main__:<module>:12 - Endogenous: 68.807021484375\n",
      "2024-03-21 12:36:08.401 | INFO     | __main__:<module>:10 - Loss for LS neuron No 40: 68.96199124785224 (Hz^2).\n",
      "2024-03-21 12:36:08.403 | INFO     | __main__:<module>:12 - Endogenous: 72.179541015625\n",
      "2024-03-21 12:36:08.597 | INFO     | __main__:<module>:10 - Loss for LS neuron No 41: 58.771303157216494 (Hz^2).\n",
      "2024-03-21 12:36:08.598 | INFO     | __main__:<module>:12 - Endogenous: 60.6742822265625\n",
      "2024-03-21 12:36:08.808 | INFO     | __main__:<module>:10 - Loss for LS neuron No 42: 1112.1097508591065 (Hz^2).\n",
      "2024-03-21 12:36:08.809 | INFO     | __main__:<module>:12 - Endogenous: 1048.600625\n",
      "2024-03-21 12:36:08.997 | INFO     | __main__:<module>:10 - Loss for LS neuron No 43: 46.94333923969072 (Hz^2).\n",
      "2024-03-21 12:36:08.998 | INFO     | __main__:<module>:12 - Endogenous: 42.464951171875\n",
      "2024-03-21 12:36:09.193 | INFO     | __main__:<module>:10 - Loss for LS neuron No 44: 92.00528216280068 (Hz^2).\n",
      "2024-03-21 12:36:09.195 | INFO     | __main__:<module>:12 - Endogenous: 92.741962890625\n",
      "2024-03-21 12:36:09.391 | INFO     | __main__:<module>:10 - Loss for LS neuron No 45: 102.00847025343643 (Hz^2).\n",
      "2024-03-21 12:36:09.392 | INFO     | __main__:<module>:12 - Endogenous: 102.138486328125\n",
      "2024-03-21 12:36:09.603 | INFO     | __main__:<module>:10 - Loss for LS neuron No 46: 16.192010309278352 (Hz^2).\n",
      "2024-03-21 12:36:09.604 | INFO     | __main__:<module>:12 - Endogenous: 16.199501953125\n",
      "2024-03-21 12:36:09.791 | INFO     | __main__:<module>:10 - Loss for LS neuron No 47: 97.23614019544674 (Hz^2).\n",
      "2024-03-21 12:36:09.792 | INFO     | __main__:<module>:12 - Endogenous: 103.93271484375\n",
      "2024-03-21 12:36:09.990 | INFO     | __main__:<module>:10 - Loss for LS neuron No 48: 98.39008134664948 (Hz^2).\n",
      "2024-03-21 12:36:09.992 | INFO     | __main__:<module>:12 - Endogenous: 98.57759765625\n",
      "2024-03-21 12:36:10.198 | INFO     | __main__:<module>:10 - Loss for LS neuron No 49: 18.368835239475946 (Hz^2).\n",
      "2024-03-21 12:36:10.199 | INFO     | __main__:<module>:12 - Endogenous: 18.3549560546875\n",
      "2024-03-21 12:36:10.400 | INFO     | __main__:<module>:10 - Loss for LS neuron No 50: 58.980012349656356 (Hz^2).\n",
      "2024-03-21 12:36:10.401 | INFO     | __main__:<module>:12 - Endogenous: 56.61375\n",
      "2024-03-21 12:36:10.652 | INFO     | __main__:<module>:10 - Loss for LS neuron No 51: 343.7967407646048 (Hz^2).\n",
      "2024-03-21 12:36:10.653 | INFO     | __main__:<module>:12 - Endogenous: 339.06296875\n",
      "2024-03-21 12:36:10.857 | INFO     | __main__:<module>:10 - Loss for LS neuron No 52: 83.99191902920963 (Hz^2).\n",
      "2024-03-21 12:36:10.859 | INFO     | __main__:<module>:12 - Endogenous: 79.2255322265625\n",
      "2024-03-21 12:36:11.048 | INFO     | __main__:<module>:10 - Loss for LS neuron No 53: 28.606408397766323 (Hz^2).\n",
      "2024-03-21 12:36:11.049 | INFO     | __main__:<module>:12 - Endogenous: 33.148779296875\n",
      "2024-03-21 12:36:11.249 | INFO     | __main__:<module>:10 - Loss for LS neuron No 54: 293.70154102233676 (Hz^2).\n",
      "2024-03-21 12:36:11.250 | INFO     | __main__:<module>:12 - Endogenous: 272.55771484375\n",
      "2024-03-21 12:36:11.460 | INFO     | __main__:<module>:10 - Loss for LS neuron No 55: 274.1536189862543 (Hz^2).\n",
      "2024-03-21 12:36:11.462 | INFO     | __main__:<module>:12 - Endogenous: 260.91876953125\n",
      "2024-03-21 12:36:11.653 | INFO     | __main__:<module>:10 - Loss for LS neuron No 56: 168.8769866838488 (Hz^2).\n",
      "2024-03-21 12:36:11.654 | INFO     | __main__:<module>:12 - Endogenous: 157.5912890625\n",
      "2024-03-21 12:36:11.842 | INFO     | __main__:<module>:10 - Loss for LS neuron No 57: 12.249236536189862 (Hz^2).\n",
      "2024-03-21 12:36:11.843 | INFO     | __main__:<module>:12 - Endogenous: 14.55901611328125\n",
      "2024-03-21 12:36:12.052 | INFO     | __main__:<module>:10 - Loss for LS neuron No 58: 204.15289411512026 (Hz^2).\n",
      "2024-03-21 12:36:12.053 | INFO     | __main__:<module>:12 - Endogenous: 162.726826171875\n",
      "2024-03-21 12:36:12.269 | INFO     | __main__:<module>:10 - Loss for LS neuron No 59: 333.3620865549828 (Hz^2).\n",
      "2024-03-21 12:36:12.270 | INFO     | __main__:<module>:12 - Endogenous: 313.58048828125\n",
      "2024-03-21 12:36:12.487 | INFO     | __main__:<module>:10 - Loss for LS neuron No 60: 344.5579359965636 (Hz^2).\n",
      "2024-03-21 12:36:12.488 | INFO     | __main__:<module>:12 - Endogenous: 326.54845703125\n",
      "2024-03-21 12:36:12.687 | INFO     | __main__:<module>:10 - Loss for LS neuron No 61: 66.85501234965636 (Hz^2).\n",
      "2024-03-21 12:36:12.688 | INFO     | __main__:<module>:12 - Endogenous: 71.113623046875\n",
      "2024-03-21 12:36:12.883 | INFO     | __main__:<module>:10 - Loss for LS neuron No 62: 16.573537505369416 (Hz^2).\n",
      "2024-03-21 12:36:12.884 | INFO     | __main__:<module>:12 - Endogenous: 15.1343896484375\n",
      "2024-03-21 12:36:13.089 | INFO     | __main__:<module>:10 - Loss for LS neuron No 63: 117.74089884020619 (Hz^2).\n",
      "2024-03-21 12:36:13.090 | INFO     | __main__:<module>:12 - Endogenous: 108.26201171875\n",
      "2024-03-21 12:36:13.288 | INFO     | __main__:<module>:10 - Loss for LS neuron No 64: 676.8542203608248 (Hz^2).\n",
      "2024-03-21 12:36:13.289 | INFO     | __main__:<module>:12 - Endogenous: 593.1033203125\n",
      "2024-03-21 12:36:13.510 | INFO     | __main__:<module>:10 - Loss for LS neuron No 65: 89.12036216709622 (Hz^2).\n",
      "2024-03-21 12:36:13.511 | INFO     | __main__:<module>:12 - Endogenous: 89.98859375\n",
      "2024-03-21 12:36:13.697 | INFO     | __main__:<module>:10 - Loss for LS neuron No 66: 295.71665592783506 (Hz^2).\n",
      "2024-03-21 12:36:13.699 | INFO     | __main__:<module>:12 - Endogenous: 292.76091796875\n",
      "2024-03-21 12:36:13.876 | INFO     | __main__:<module>:10 - Loss for LS neuron No 67: 16.175615133698454 (Hz^2).\n",
      "2024-03-21 12:36:13.877 | INFO     | __main__:<module>:12 - Endogenous: 17.593992919921874\n",
      "2024-03-21 12:36:14.074 | INFO     | __main__:<module>:10 - Loss for LS neuron No 68: 154.497879080756 (Hz^2).\n",
      "2024-03-21 12:36:14.076 | INFO     | __main__:<module>:12 - Endogenous: 154.35826171875\n",
      "2024-03-21 12:36:14.281 | INFO     | __main__:<module>:10 - Loss for LS neuron No 69: 217.8855106314433 (Hz^2).\n",
      "2024-03-21 12:36:14.282 | INFO     | __main__:<module>:12 - Endogenous: 209.3849609375\n",
      "2024-03-21 12:36:14.466 | INFO     | __main__:<module>:10 - Loss for LS neuron No 70: 30.686127443084192 (Hz^2).\n",
      "2024-03-21 12:36:14.467 | INFO     | __main__:<module>:12 - Endogenous: 23.35158203125\n",
      "2024-03-21 12:36:14.669 | INFO     | __main__:<module>:10 - Loss for LS neuron No 71: 357.968776847079 (Hz^2).\n",
      "2024-03-21 12:36:14.670 | INFO     | __main__:<module>:12 - Endogenous: 338.055078125\n",
      "2024-03-21 12:36:14.872 | INFO     | __main__:<module>:10 - Loss for LS neuron No 72: 312.7563090635739 (Hz^2).\n",
      "2024-03-21 12:36:14.873 | INFO     | __main__:<module>:12 - Endogenous: 322.3139453125\n",
      "2024-03-21 12:36:15.061 | INFO     | __main__:<module>:10 - Loss for LS neuron No 73: 23.822346166237114 (Hz^2).\n",
      "2024-03-21 12:36:15.062 | INFO     | __main__:<module>:12 - Endogenous: 21.2516943359375\n",
      "2024-03-21 12:36:15.235 | INFO     | __main__:<module>:10 - Loss for LS neuron No 74: 30.677929016323024 (Hz^2).\n",
      "2024-03-21 12:36:15.237 | INFO     | __main__:<module>:12 - Endogenous: 27.0478662109375\n",
      "2024-03-21 12:36:15.482 | INFO     | __main__:<module>:10 - Loss for LS neuron No 75: 319.32957474226805 (Hz^2).\n",
      "2024-03-21 12:36:15.483 | INFO     | __main__:<module>:12 - Endogenous: 298.332890625\n",
      "2024-03-21 12:36:15.673 | INFO     | __main__:<module>:10 - Loss for LS neuron No 76: 234.62360395189003 (Hz^2).\n",
      "2024-03-21 12:36:15.674 | INFO     | __main__:<module>:12 - Endogenous: 215.35984375\n",
      "2024-03-21 12:36:15.676 | INFO     | __main__:<module>:14 - Pred mean overall loss: 231.81675369304236\n",
      "2024-03-21 12:36:15.677 | INFO     | __main__:<module>:15 - GLM with identity function overall loss: 234.6309189092694\n",
      "/tmp/ipykernel_54563/2695946135.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  logger.info(f'GLM prediction for forward stim R2 loss: {glm_LS_losses[forward_mse_idx].sum()/len(forward_mse_idx)/output_dim}')\n",
      "2024-03-21 12:36:15.678 | INFO     | __main__:<module>:17 - GLM prediction for forward stim R2 loss: nan\n",
      "/tmp/ipykernel_54563/2695946135.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  logger.info(f'GLM prediction for backward stim R2 loss: {glm_LS_losses[backward_mse_idx].sum() / len(backward_mse_idx)/output_dim}')\n",
      "2024-03-21 12:36:15.679 | INFO     | __main__:<module>:18 - GLM prediction for backward stim R2 loss: nan\n",
      "/tmp/ipykernel_54563/2695946135.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "  logger.info(f'GLM prediction for random stim R2 loss: {glm_LS_losses[random_mse_idx].sum() / len(random_mse_idx)/output_dim}')\n",
      "2024-03-21 12:36:15.680 | INFO     | __main__:<module>:19 - GLM prediction for random stim R2 loss: nan\n",
      "2024-03-21 12:36:15.682 | INFO     | __main__:<module>:20 - GLM prediction for non-stim stim R2 loss: 227.72068181818182\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'save/trained_models/AUG23/AUG23-stim-LS-glm-losses.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLM prediction for random stim R2 loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglm_LS_losses[random_mse_idx]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(random_mse_idx)\u001b[38;5;241m/\u001b[39moutput_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLM prediction for non-stim stim R2 loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglm_LS_losses[non_stim_mse_idx]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(non_stim_mse_idx)\u001b[38;5;241m/\u001b[39moutput_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAUG23-stim-LS-glm-losses.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglm_LS_losses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/numpy/lib/npyio.py:542\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    541\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'save/trained_models/AUG23/AUG23-stim-LS-glm-losses.npy'"
     ]
    }
   ],
   "source": [
    "# pred for each neuron\n",
    "glm_LS_losses = np.zeros_like(Y_test_LS_np) # (500, 8)\n",
    "output_dim = Y_test_LS_np.shape[1]\n",
    "\n",
    "for i in range(output_dim):\n",
    "    glm_LS_reg = TweedieRegressor(power=0, alpha=1, link='auto')\n",
    "    glm_LS_reg.fit(X_train_np, Y_train_LS_np[:,i])\n",
    "    \n",
    "    glm_LS_losses[:,i] += np.power(Y_test_LS_np[:,i] - glm_LS_reg.predict(X_test_np), 2)\n",
    "    logger.info(f'Loss for LS neuron No {i}: {glm_LS_losses[:,i].sum() / Y_test_LS_np.shape[0]} (Hz^2).')\n",
    "    # logger.info(f'Forward: {glm_LS_losses[forward_mse_idx,i].sum() / len(forward_mse_idx)}, Backward: {glm_LS_losses[backward_mse_idx,i].sum() / len(backward_mse_idx)}, Random: {glm_LS_losses[random_mse_idx, i].sum() / len(random_mse_idx)}. Endogenous: {glm_LS_losses[non_stim_mse_idx, i].sum() / len(non_stim_mse_idx)}')\n",
    "    logger.info(f'Endogenous: {glm_LS_losses[non_stim_mse_idx, i].sum() / len(non_stim_mse_idx)}')\n",
    "                \n",
    "logger.info(f'Pred mean overall loss: {np.power(Y_test_LS_np - Y_test_LS_np.mean(0), 2).sum() / np.prod(Y_test_LS_np.shape)}')\n",
    "logger.info(f'GLM with identity function overall loss: {glm_LS_losses.sum() / np.prod(Y_test_LS.shape)}')\n",
    "\n",
    "logger.info(f'GLM prediction for forward stim R2 loss: {glm_LS_losses[forward_mse_idx].sum()/len(forward_mse_idx)/output_dim}')\n",
    "logger.info(f'GLM prediction for backward stim R2 loss: {glm_LS_losses[backward_mse_idx].sum() / len(backward_mse_idx)/output_dim}')\n",
    "logger.info(f'GLM prediction for random stim R2 loss: {glm_LS_losses[random_mse_idx].sum() / len(random_mse_idx)/output_dim}')\n",
    "logger.info(f'GLM prediction for non-stim stim R2 loss: {glm_LS_losses[non_stim_mse_idx].sum() / len(non_stim_mse_idx)/output_dim}')\n",
    "\n",
    "np.save(save_path / 'AUG23-stim-LS-glm-losses.npy', glm_LS_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 12:38:51.659 | INFO     | __main__:<module>:2 - Predicting mean for each of the LS neurons: [2.79635712e+02 2.11294060e+01 1.11091971e+00 5.29171875e+02\n",
      " 8.94189636e+02 9.85677624e+00 1.96000600e+00 2.45343246e+02\n",
      " 7.29042419e+02 3.44409271e+02 4.24227081e+02 4.17588287e+02\n",
      " 9.30177856e+02 8.75066147e+01 7.23530054e+00 3.33335968e+02\n",
      " 1.32261584e+03 3.77745728e+02 6.55584595e+02 6.48848145e+02\n",
      " 4.46403313e+01 6.80087402e+02 3.64966393e+01 1.53469147e+02\n",
      " 8.72814819e+02 6.40976410e+01 3.20763550e+02 1.08578444e+01\n",
      " 2.35960655e+01 7.06837797e+00 5.47306967e+00 3.24718513e+01\n",
      " 5.25619850e+01 5.92391281e+01 1.98560196e+02 5.53070307e+00\n",
      " 7.27383652e+01 1.33449066e+02 3.51074295e+01 5.98813820e+01\n",
      " 7.23470001e+01 6.11032944e+01 1.05054114e+03 4.67543335e+01\n",
      " 1.06549324e+02 1.01287361e+02 1.39773540e+01 9.44899826e+01\n",
      " 9.06082535e+01 1.41042509e+01 5.32822037e+01 3.42938934e+02\n",
      " 8.32894135e+01 2.33923607e+01 3.08379578e+02 2.58968994e+02\n",
      " 1.69481491e+02 1.29877052e+01 1.92107208e+02 2.78744568e+02\n",
      " 3.16301514e+02 7.33614655e+01 1.68479500e+01 1.24638115e+02\n",
      " 7.29259216e+02 8.91242218e+01 3.28300934e+02 1.59545860e+01\n",
      " 1.38480331e+02 2.25109634e+02 3.56827621e+01 3.51083984e+02\n",
      " 3.05711884e+02 2.14160805e+01 2.70685749e+01 3.03304657e+02\n",
      " 2.43288208e+02]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm_LS_losses = np.load(save_path / 'AUG23-stim-LS-glm-losses.npy')\n",
    "logger.info(f'Predicting mean for each of the LS neurons: {np.power(Y_test_LS_np - Y_test_LS_np.mean(0), 2).sum(0) / Y_test_LS_np.shape[0]}')\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(np.arange(output_dim), np.sqrt(glm_LS_losses.mean(0)), width=0.1, label='overall')\n",
    "# plt.bar(np.arange(8)-0.1, np.sqrt(glm_LS_losses[forward_mse_idx].mean(0)), width=0.1, label='forward')\n",
    "# plt.bar(np.arange(8), np.sqrt(glm_LS_losses[backward_mse_idx].mean(0)), width=0.1, label='backward')\n",
    "# plt.bar(np.arange(8)+0.1, np.sqrt(glm_LS_losses[random_mse_idx].mean(0)), width=0.1, label='random')\n",
    "# plt.bar(np.arange(8)+0.2, np.sqrt(glm_LS_losses[non_stim_mse_idx].mean(0)), width=0.1, label='endogenous')\n",
    "plt.xlabel('LS neuron idx')\n",
    "plt.ylabel('Absolute Prediction error (Hz)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
